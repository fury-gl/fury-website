<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://fury.gl/</id>
  <title>Blog - Posted in 2024</title>
  <updated>2024-06-07T10:10:02.067428+00:00</updated>
  <link href="https://fury.gl/"/>
  <link href="https://fury.gl/blog/2024/atom.xml" rel="self"/>
  <generator uri="https://ablog.readthedocs.io/" version="0.11.10">ABlog</generator>
  <entry>
    <id>https://fury.gl/posts/2024/2024-05-28-week-0-robin.html</id>
    <title>Week 0: Community Bonding!</title>
    <updated>2024-05-29T00:00:00+00:00</updated>
    <author>
      <name>Robin Roy</name>
    </author>
    <content type="html">&lt;section id="week-0-community-bonding"&gt;

&lt;p&gt;Hi, I‚Äôm Robin and I‚Äôm a 2nd year CS undergrad from Vellore Institute of Technology, Chennai. During GSoC ‚Äò24 my work will be to build an LLM chatbot which will help the community by answering their questions.&lt;/p&gt;
&lt;p&gt;Scientific visualization is often complicated and hard for people to get used to - ‚ÄúAlthough 3D visualization technologies are advancing quickly, their sophistication and focus on non-scientific domains makes it hard for researchers to use
them. In other words, most of the existing 3D visualization and computing APIs are low-level
(close to the hardware) and made for professional specialist developers.‚Äù &lt;a class="reference internal" href="../posts/2024/2024-05-28-week-0-robin.html#fury" id="id1"&gt;&lt;span&gt;[FURY]&lt;/span&gt;&lt;/a&gt;. FURY is our effort to bridge this gap with an easy-to-use API. With LLMs, the goal is to take this one step further and make it even simpler for people to get started. By reducing the barrier to entry, we can bring more people into this domain. Visualization should not be the most time-consuming thing for an engineer/researcher, it is supposed to just happen and help them accelerate faster.&lt;/p&gt;
&lt;section id="my-community-bonding-work"&gt;
&lt;h2&gt;My Community Bonding Work&lt;/h2&gt;
&lt;p&gt;The main goal for me was to try different hosting providers and LLMs, test everything and see how they perform. I had my final exams during this period so I lost around 2 weeks to that. But I did manage to catch up and finish the work.
We wanted to keep hosting cheap (preferably free). I‚Äôll detail all the things I tried and the review for each of them.&lt;/p&gt;
&lt;section id="hosting-work-in-order"&gt;
&lt;h3&gt;Hosting work, in order:&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ollama on Google Colab&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The way it works is by taking Ollama and running it inside google colab, then providing a reverse proxy using ngrok.
We later connect that reverse proxy to the local ollama instance.&lt;/p&gt;
&lt;p&gt;It works. But Google Colab can run only for a maximum of 12 hours and the runtimes will timeout if idle. Also, it was very hacky.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe width="640" height="390" src="https://drive.google.com/file/d/1qNLtXxAMlLQ8xO8jfV0keRtskvcsj-fC/preview" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ollama on Kaggle&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-05-28-week-0-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú2‚Äù (ordinal 2)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;Same as above, same issues. Talked with my mentor &lt;a class="reference external" href="https://github.com/m-agour"&gt;Mohamed&lt;/a&gt; and skipped implementation.&lt;/p&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;GGUF (GPT-Generated Unified Format) models with ctransformers on HuggingFace&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-05-28-week-0-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú3‚Äù (ordinal 3)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;The way it works is by taking a &lt;a class="reference external" href="https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/"&gt;gguf&lt;/a&gt; model and then inferencing using the ctransformers library from HuggingFace. An endpoint will be exposed using flask/fastapi.&lt;/p&gt;
&lt;p&gt;It had issues like not all models were working, and ctransformers did not support all models. And the models that do work were slow on my machine. Local testing was a nightmare and inference speed on HuggingFace was also very slow.&lt;/p&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;GGUF models with llama-cpp-python, hosted on HuggingFace&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-05-28-week-0-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú4‚Äù (ordinal 4)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I used langchain wrapper over llama-cpp-python to inference GGUF models. This one was able to handle all GGUF models, and local testing was okayish. When I tried handling concurrent requests, it crashed and gave segmentation fault. I fixed segmentation fault later by increasing gunicorn workers (Gunicorn was the WSGI server I used).
It was still not that good and local testing was annoying me. I cannot iterate fast when it takes a full 2-3 minutes for the output to generate.&lt;/p&gt;
&lt;p&gt;This wrapper on a wrapper on a wrapper was also not fun (langchain wrapper of llama-cpp-python which itself is a wrapper of llama-cpp).&lt;/p&gt;
&lt;p&gt;I later removed langchain and reimplemented everything, but langchain wasn‚Äôt the reason for the slow performance so it wasn‚Äôt helpful.&lt;/p&gt;
&lt;ol class="arabic simple" start="5"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ollama on HuggingFace!&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-05-28-week-0-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú5‚Äù (ordinal 5)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;TLDR: This one worked!&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe width="640" height="390" src="https://drive.google.com/file/d/17yxdw169uqLlw6WKfi--bWEUQArJk7i2/preview" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;Ollama was perfect, it works like a charm on my machine and the ecosystem is also amazing (the people on their discord server are super kind). I knew I had to try ollama on HuggingFace.
I was unable to initially run ollama and provide an endpoint. My dockerfile builds were all failing. Later mentor &lt;a class="reference external" href="https://github.com/skoudoro/"&gt;Serge&lt;/a&gt; told me to use the official Ollama image (till then I was using the Ubuntu base image).&lt;/p&gt;
&lt;p&gt;I managed to get the dockerfile running locally, but still, the HuggingFace build was failing. Then I took help from HuggingFace community. They told me it was HuggingFace blocking some ports, so to try different ports. This is when I came across another ollama server repo, and it was using Ubuntu as the base image. I studied that code and modified my dockerfile. It was adding an env variable to repo settings that I missed. My current dockerfile is just 5 lines and it works well.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="fury-discord-bot"&gt;
&lt;h3&gt;FURY Discord Bot&lt;/h3&gt;
&lt;p&gt;I also made a barebones FURY Discord Bot which was connected to my local ollama instance. My dockerfile was stuck and I wanted to do something tangible, so I did this before the weekly meeting.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe src="https://drive.google.com/file/d/17aosa4iyDl90mYfVGPrmILtQdXtS6IEy/preview" width="640" height="480" allow="autoplay"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="what-is-coming-up-next-week"&gt;
&lt;h2&gt;What is coming up next week?&lt;/h2&gt;
&lt;p&gt;Currently, I‚Äôm finding a vector DB &amp;amp; studying how to effectively use RAG here.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="did-you-get-stuck-anywhere"&gt;
&lt;h2&gt;Did you get stuck anywhere?&lt;/h2&gt;
&lt;p&gt;Yes, I had some issues with the dockerfile. It was resolved.&lt;/p&gt;
&lt;p&gt;LINKS:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-bot/tree/main"&gt;HuggingFace repo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/robinroy03/fury-discord-bot"&gt;Discord Bot&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;div role="list" class="citation-list"&gt;
&lt;div class="citation" id="fury" role="doc-biblioentry"&gt;
&lt;span class="label"&gt;&lt;span class="fn-bracket"&gt;[&lt;/span&gt;&lt;a role="doc-backlink" href="#id1"&gt;FURY&lt;/a&gt;&lt;span class="fn-bracket"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;p&gt;Eleftherios Garyfallidis, Serge Koudoro, Javier Guaje, Marc-Alexandre C√¥t√©, Soham Biswas, David Reagan, Nasim Anousheh, Filipi Silva, Geoffrey Fox, and Fury Contributors. ‚ÄúFURY: advanced scientific visualization.‚Äù Journal of Open Source Software 6, no. 64 (2021): 3384. &lt;a class="reference external" href="https://doi.org/10.21105/joss.03384"&gt;https://doi.org/10.21105/joss.03384&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-05-28-week-0-robin.html"/>
    <summary>Hi, I‚Äôm Robin and I‚Äôm a 2nd year CS undergrad from Vellore Institute of Technology, Chennai. During GSoC ‚Äò24 my work will be to build an LLM chatbot which will help the community by answering their questions.</summary>
    <category term="google" label="google"/>
    <published>2024-05-29T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-05-28-first-post-wachiou-bouraima.html</id>
    <title>WEEK 0: The beginning of my journey in Google Summer of Code (GSoC) 2024</title>
    <updated>2024-05-28T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-0-the-beginning-of-my-journey-in-google-summer-of-code-gsoc-2024"&gt;

&lt;section id="here-we-go"&gt;
&lt;h2&gt;Here we go‚Ä¶..&lt;/h2&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Hello and welcome to my GSoC 24 journey, I‚Äôm Wachiou Bouraima pronounced (Wasiu Ibrahima).&lt;/div&gt;
&lt;div class="line"&gt;&lt;br /&gt;&lt;/div&gt;
&lt;div class="line"&gt;First of all, I‚Äôd like to express my deep gratitude for this immense opportunity.&lt;/div&gt;
&lt;div class="line"&gt;In this first article, yes you read ‚Äúfirst article‚Äù correctly, as it won‚Äôt be the only one, I‚Äôm going to share with you my first adventures in GSoC‚Äô24. Happy read&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section id="welcome-and-integration-into-the-community"&gt;
&lt;h2&gt;Welcome and integration into the community.&lt;/h2&gt;
&lt;p&gt;Like any good start, this week I have the incredible opportunity to be welcomed into the community by the Core Team and my Mentor himself, during this session the Mentors welcomed us warmly and also congratulated us. They shared with us the rules respected during and after the GSoC program. This session made me feel comfortable and confident.&lt;/p&gt;
&lt;p&gt;I also have to admit that the mentors are experienced and willing to share their knowledge, which I really appreciate. I also got to know the DIPY and FURY community members.&lt;/p&gt;
&lt;p&gt;Not only that, but I also attended the GSoC‚Äô24 summit organised by Google. This session was very informative and aimed to ease our way into GSoC‚Äô24, and help us avoid certain mistakes during and after the program.
I was able to meet the other GSoC students, and I must say that they are all very talented and motivated. I am very happy to be part of this community.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="project-details"&gt;
&lt;h2&gt;Project details&lt;/h2&gt;
&lt;p&gt;I will work on the project: &lt;strong&gt;Modernization of the FURY code base to improve readability, maintainability and performance&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This project aims to modernize the FURY code base by implementing keyword-only arguments to improve code clarity and explicit parameter passing. In addition, the integration of lazy loading functionality will optimize performance by loading resources only when they are needed. Finally, active participation in code refactoring efforts will improve the structure and maintainability of the FURY code base. The project will result in a modernized code base, comprehensive unit testing, updated Sphinx documentation and public presentations illustrating the improvements and benefits. Ultimately, the aim is to significantly improve the FURY code base for future developers and users.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="weekly-tasks"&gt;
&lt;h2&gt;Weekly tasks&lt;/h2&gt;
&lt;p&gt;I had to work on my first mission of the adventure, which was to create a decorator named &lt;strong&gt;keyword_only&lt;/strong&gt; to ensure that all arguments after the first are keyword arguments only. It also checks that all keyword arguments are expected by the function. You can check what I had to do in this Pull Request : &lt;a class="github reference external" href="https://github.com/fury-gl/fury/pull/888"&gt;fury-gl/fury#888&lt;/a&gt;. I‚Äôve learned a lot from implementing the &lt;strong&gt;keyword_only&lt;/strong&gt; decorator&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-s-next"&gt;
&lt;h2&gt;What‚Äôs next?&lt;/h2&gt;
&lt;p&gt;For my next task, I‚Äôll first apply the advice and comments from my first task, adding the &lt;strong&gt;keyword_only&lt;/strong&gt; decorator after all the necessary reviews and member approval, on all the functions concerned next, then I‚Äôll start and finish, integrating the lazy loading feature.&lt;/p&gt;
&lt;p&gt;ü•∞ Thank you for reading. Your comments are most welcome, and I learn from them.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-05-28-first-post-wachiou-bouraima.html"/>
    <summary>Like any good start, this week I have the incredible opportunity to be welcomed into the community by the Core Team and my Mentor himself, during this session the Mentors welcomed us warmly and also congratulated us. They shared with us the rules respected during and after the GSoC program. This session made me feel comfortable and confident.</summary>
    <category term="google" label="google"/>
    <published>2024-05-28T00:00:00+00:00</published>
  </entry>
</feed>
