<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://fury.gl/</id>
  <title>Blog - Posted in 2024</title>
  <updated>2024-06-24T21:15:40.173380+00:00</updated>
  <link href="https://fury.gl/"/>
  <link href="https://fury.gl/blog/2024/atom.xml" rel="self"/>
  <generator uri="https://ablog.readthedocs.io/" version="0.11.10">ABlog</generator>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-15-week2-wachiou-bouraima.html</id>
    <title>WEEK 2: Refinements and Further Enhancements</title>
    <updated>2024-06-15T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-2-refinements-and-further-enhancements"&gt;

&lt;section id="hello-again"&gt;
&lt;h2&gt;Hello again,&lt;/h2&gt;
&lt;p&gt;Welcome back to my Google Summer of Code (GSoC) 2024 journey! This week has been dedicated to refining and improving the work done so far, with a particular focus on the keyword_only decorator.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="renaming-and-updating-the-decorator"&gt;
&lt;h2&gt;Renaming and Updating the Decorator&lt;/h2&gt;
&lt;p&gt;This week, I‚Äôve updated &lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/888"&gt;this Pull Request&lt;/a&gt; by renaming the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;keyword_only&lt;/span&gt;&lt;/code&gt; decorator to &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; for greater clarity. The updated decorator now includes version parameters from_version and until_version. This enhancement ensures that the decorator will raise a RuntimeError if the current version of FURY is greater than until_version.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="peer-code-review"&gt;
&lt;h2&gt;Peer Code Review&lt;/h2&gt;
&lt;p&gt;I also spent time reviewing &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka‚Äôs&lt;/a&gt; code. This exercise remains rewarding, as it helps me understand different coding styles and approaches. Constructive feedback and suggestions from my classmates were invaluable, not only in helping my teammates but also in improving my own coding and reviewing skills.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="research-into-lazy-loading"&gt;
&lt;h2&gt;Research into lazy loading&lt;/h2&gt;
&lt;p&gt;In parallel, I started researching the lazy loading feature and thinking about how to implement it. This feature will optimize performance by loading resources only when they‚Äôre needed, which is crucial to improving the efficiency of FURY‚Äôs code base.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="acknowledgements"&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;I am deeply grateful to my classmates &lt;a class="reference external" href="https://github.com/itellaetxe"&gt;I√±igo Tellaetxe Elorriaga&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin Roy&lt;/a&gt;, and &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka&lt;/a&gt; for their insightful suggestions and comments on my work.
Special thanks to my mentor, &lt;a class="reference external" href="https://github.com//skoudoro"&gt;Serge Koudoro&lt;/a&gt;, whose guidance and support enabled me to meet the challenges of this project.
Their combined efforts have greatly contributed to my progress, and I appreciate their continued help.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-happens-next"&gt;
&lt;h2&gt;What happens next?&lt;/h2&gt;
&lt;p&gt;For week 3, I plan to :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Ensure that the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator is applied consistently in all necessary functions.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Continue to update the calling of these functions in the code to maintain consistency and avoid warnings.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Refine decorator as necessary based on feedback and testing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Start implementing lazy loading functionality based on my research to optimize performance.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ü•∞ Thank you for taking the time to follow my progress. Your feedback is always welcome and I look forward to sharing more updates with you next week.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-15-week2-wachiou-bouraima.html"/>
    <summary>Welcome back to my Google Summer of Code (GSoC) 2024 journey! This week has been dedicated to refining and improving the work done so far, with a particular focus on the keyword_only decorator.</summary>
    <category term="google" label="google"/>
    <published>2024-06-15T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-06-week-1-robin.html</id>
    <title>Week 1: It officially begins‚Ä¶</title>
    <updated>2024-06-06T00:00:00+00:00</updated>
    <author>
      <name>Robin Roy</name>
    </author>
    <content type="html">&lt;section id="week-1-it-officially-begins"&gt;

&lt;p&gt;Hi, I‚Äôm &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin&lt;/a&gt; and this is my blog about week 1.&lt;/p&gt;
&lt;p&gt;My goal for week 1 was to start with &lt;a class="reference external" href="https://www.pinecone.io/learn/retrieval-augmented-generation/"&gt;Retrieval-Augmented Generation (RAG)&lt;/a&gt;, check different databases and host every endpoint. My week1 and week2 are very intertwined because I applied everything I did during week1 on week2. (I‚Äôm writing this blog midway through week2)&lt;/p&gt;
&lt;section id="why-phi-3-mini-4k-instruct"&gt;
&lt;h2&gt;why phi-3-mini-4k-instruct?&lt;/h2&gt;
&lt;p&gt;Before I detail everything I‚Äôve done this week, I‚Äôll explain why &lt;a class="reference external" href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct"&gt;phi-3 mini 4k&lt;/a&gt; was chosen as the LLM, I forgot to mention this in the last blog. Phi-3 is a small 3.8B 4k context model, it means it can work with 4k tokens(similar to words) at a time. Due to its small size, it runs fast both locally and on Huggingface. Performance wise comparatively with other opensource models, it performs decently well. In the &lt;a class="reference external" href="https://chat.lmsys.org/?leaderboard"&gt;LMSYS LLM leaderboard&lt;/a&gt; phi-3 mini 4k comes with an ELO of 1066 (59th position). But it achieves this as a small model.
I also tried Llama3-8B, it performs better than phi-3 mini with an ELO of 1153 and rank 22. But it is considerably slower for inference. Due to this, I chose phi-3 mini for now.&lt;/p&gt;
&lt;section id="things-i-did-week-1-and-some-week2"&gt;
&lt;h3&gt;Things I did week-1 (and some week2)&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Choosing the vector database&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I decided to choose &lt;a class="reference external" href="https://www.pinecone.io/"&gt;Pinecone&lt;/a&gt; as the vector DB because it had a very generous free tier. Other options on consideration were &lt;a class="reference external" href="https://github.com/pgvector/pgvector"&gt;pgvector&lt;/a&gt; and &lt;a class="reference external" href="https://www.trychroma.com/"&gt;chromadb&lt;/a&gt;, but they didn‚Äôt have a free tier.&lt;/p&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PR Submissions and Review&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú2‚Äù (ordinal 2)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I also merged a &lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/891"&gt;PR&lt;/a&gt; on FURY which fixes a CI issue. I also spent time doing review of other PRs from my fellow GSoC mates.&lt;/p&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Deciding which embedding model to use&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú3‚Äù (ordinal 3)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;A good embedding model is necessary to generate embeddings which we then upsert into the DB. Ollama had embedding model support, but I found the catalogue very small and the models they provided were not powerful enough. Therefore I decided to try using HuggingFace Sentence Transformers.
Sentence Transformers have a very vibrant catalogue of models available of various sizes. I chose &lt;a class="reference external" href="https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5"&gt;gte-large-en-v1.5&lt;/a&gt; from Alibaba-NLP, an 8k context, 434 million parameter model. It only had a modest memory requirement of 1.62 GB.
Performance wise, it ranks 11th on the &lt;a class="reference external" href="https://huggingface.co/spaces/mteb/leaderboard"&gt;MTEB leaderboard&lt;/a&gt;. It is a very interesting model due to its size:performance ratio.&lt;/p&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hosting the embedding model&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú4‚Äù (ordinal 4)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;Hosting this sentence-transformer model was confusing. For some reason, the HF spaces were blocking the Python script from writing on &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;.cache&lt;/span&gt;&lt;/code&gt; folder. Docker container inside spaces runs with user id 1000 (non-root user), therefore I had to give it permission to download and store files.&lt;/p&gt;
&lt;p&gt;I‚Äôve hosted 5 gunicorn workers to serve 5 parallel requests at a time. Since the model is small, this is possible.&lt;/p&gt;
&lt;ol class="arabic simple" start="5"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hosting the database endpoint&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú5‚Äù (ordinal 5)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I wrapped the pinecone DB API into an endpoint so it‚Äôll be easy to query and receive the results.
It is also configured to accept 5 concurrent requests although I could increase it a lot more.&lt;/p&gt;
&lt;p&gt;I upserted docstrings from &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;fury/actor.py&lt;/span&gt;&lt;/code&gt; into the vector DB for testing. So now, whenever you ask a question the model will use some &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;actor.py&lt;/span&gt;&lt;/code&gt; function to give you an answer. For now, it could be used like a semantic function search engine.&lt;/p&gt;
&lt;p&gt;I decided to abstract the DB endpoint to reduce the dependency on one provider. We can swap the providers as required and keep all other features running.&lt;/p&gt;
&lt;ol class="arabic simple" start="6"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hosting Discord Bot&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú6‚Äù (ordinal 6)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;So with this, all the endpoints are finally online. The bot has some issues, it is going offline midway for some reason. I‚Äôll have to see why that happens.&lt;/p&gt;
&lt;p&gt;For some reason, Huggingface spaces decided to not start the bot script. Later a community admin from Huggingface told me to use their official bot implementation as a reference. This is why I had to use threading and gradio to get the bot running (migrating to docker can be done, but this is how they did it and I just took that for now).&lt;/p&gt;
&lt;p&gt;Huggingface spaces need a script to satisfy certain criteria to allow them to run, one of them is a non-blocking I/O on the main loop. So I had to move the discord bot to a new thread.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="connecting-all-of-them-together"&gt;
&lt;h2&gt;Connecting all of them together!&lt;/h2&gt;
&lt;dl class="simple"&gt;
&lt;dt&gt;So now we have 4 hosted services, all hosted on HuggingFace spaces:&lt;/dt&gt;&lt;dd&gt;&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Discord Bot&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;LLM API&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Embeddings API&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Database API&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Now we‚Äôll have to connect them all to get an answer to the user query.&lt;/p&gt;
&lt;p&gt;This is the current architecture, there‚Äôs a lot of room for improvement here.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;img src="https://github.com/fury-gl/fury-communication-assets/blob/main/gsoc_2024/7-6-2024-demo-architecture-gsoc-robin-week2.png?raw=true"&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;The Language Model takes the context and the user query, combines them to form an answer and returns to the user through discord (for now). Maybe moving the core logic from discord bot to a separate node might be good, and connect discord/github/X to that node.
The database takes embeddings and do an Approximate Nearest Neighbor search (a variant of KNN) and returns top-k results (k=3 for now).&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe src="https://github.com/robinroy03/fury-discord-bot/assets/115863770/48f1136d-18a5-45ee-aa22-0a3f6426d575" width="640" height="390" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;section id="what-is-coming-up-next-week"&gt;
&lt;h3&gt;What is coming up next week?&lt;/h3&gt;
&lt;p&gt;Answer quality improvements. Also, the discord bot dies randomly, have to fix that also.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="did-you-get-stuck-anywhere"&gt;
&lt;h3&gt;Did you get stuck anywhere?&lt;/h3&gt;
&lt;p&gt;Was stuck in hosting models on Huggingface spaces, fixed it later.&lt;/p&gt;
&lt;p&gt;LINKS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-bot-discord/tree/main"&gt;Discord Bot&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-db-endpoint/tree/main"&gt;Database Repo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-embeddings-endpoint/tree/main"&gt;Embedding Repo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-bot/tree/main"&gt;LLM Repo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id1"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúretrieval-augmented generation (rag)‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.pinecone.io/learn/retrieval-augmented-generation/"&gt;Retrieval-Augmented Generation (RAG)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id2"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúphi-3 mini 4k‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct"&gt;phi-3 mini 4k&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id3"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúlmsys llm leaderboard‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://chat.lmsys.org/?leaderboard"&gt;LMSYS LLM leaderboard&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id4"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúpinecone‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.pinecone.io/"&gt;Pinecone&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id5"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúpgvector‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/pgvector/pgvector"&gt;pgvector&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id6"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúchromadb‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.trychroma.com/"&gt;chromadb&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id7"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúpr‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/891"&gt;PR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id8"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúgte-large-en-v1.5‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5"&gt;gte-large-en-v1.5&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id9"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: ‚Äúmteb leaderboard‚Äù.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/mteb/leaderboard"&gt;MTEB leaderboard&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-06-week-1-robin.html"/>
    <summary>Hi, I‚Äôm Robin and this is my blog about week 1.</summary>
    <category term="google" label="google"/>
    <published>2024-06-06T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-06-week1-wachiou-bouraima.html</id>
    <title>WEEK 1: Progress and challenges at Google Summer of Code (GSoC) 2024</title>
    <updated>2024-06-06T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-1-progress-and-challenges-at-google-summer-of-code-gsoc-2024"&gt;

&lt;p&gt;Helloüëãüèæ,&lt;/p&gt;
&lt;p&gt;Welcome back to my Google Summer of Code (GSoC) 2024 journey!
This week has been filled with progress and challenges as I continue to work on modernizing the FURY code base.&lt;/p&gt;
&lt;section id="applying-the-keyword-only-decorator"&gt;
&lt;h2&gt;Applying the keyword_only decorator&lt;/h2&gt;
&lt;p&gt;My main task this week was to apply the keyword_only decorator to several functions.
The decorator ensures that all arguments except the first are keyword-only,
which helps to make the code clearer and parameter passing more explicit.
Some warnings appeared after applying this decorator, and to resolve them,
I updated all the code where these functions were called with the necessary format. This was a very important step in maintaining the integrity and functionality of the code base.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="managing-the-challenges-of-git-rebasing"&gt;
&lt;h2&gt;Managing the challenges of Git rebasing&lt;/h2&gt;
&lt;p&gt;Rebasing the branch I was working on was the other major activity of my week.
It was a real challenge because of the conflicts that arose and had to be resolved.
It involved a lot of research and problem-solving on how to resolve these conflicts,
which greatly enhanced my understanding of Git. It was a challenging but satisfying experience of version control management and complex mergers.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="peer-code-review"&gt;
&lt;h2&gt;Peer code review&lt;/h2&gt;
&lt;p&gt;In addition to my duties, I was also tasked with reviewing the code of my peers.
This exercise was very rewarding, as it enabled me to understand different coding styles and approaches.
The constructive comments and suggestions were beneficial not only for teammates,
but also for improving my own coding and reviewing skills.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="acknowledgements"&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;I would like to thank all my classmates: &lt;a class="reference external" href="https://github.com/itellaetxe"&gt;I√±igo Tellaetxe Elorriaga&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin Roy&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka&lt;/a&gt; and my guide: &lt;a class="reference external" href="https://github.com//skoudoro"&gt;Serge Koudoro&lt;/a&gt; for their constructive suggestions on my work.
Their ideas and suggestions were of great help to me and I am grateful for their support and advice.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-happens-next"&gt;
&lt;h2&gt;What happens next?&lt;/h2&gt;
&lt;p&gt;Here‚Äôs a summary of what I plan to do in week two:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Apply the keyword_only decorator to all other necessary functions.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update the calling of these functions in the code to ensure consistency and avoid raising warnings.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rename the decorator with a more descriptive name.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add two parameters to the decorator, specifying from which version of FURY it will work.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ü•∞Thanks for reading! Your comments are most welcome, and I look forward to giving you a sneak preview of my work next week.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-06-week1-wachiou-bouraima.html"/>
    <summary>Helloüëãüèæ,</summary>
    <category term="google" label="google"/>
    <published>2024-06-06T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-05-28-week-0-robin.html</id>
    <title>Week 0: Community Bonding!</title>
    <updated>2024-05-29T00:00:00+00:00</updated>
    <author>
      <name>Robin Roy</name>
    </author>
    <content type="html">&lt;section id="week-0-community-bonding"&gt;

&lt;p&gt;Hi, I‚Äôm Robin and I‚Äôm a 2nd year CS undergrad from Vellore Institute of Technology, Chennai. During GSoC ‚Äò24 my work will be to build an LLM chatbot which will help the community by answering their questions.&lt;/p&gt;
&lt;p&gt;Scientific visualization is often complicated and hard for people to get used to - ‚ÄúAlthough 3D visualization technologies are advancing quickly, their sophistication and focus on non-scientific domains makes it hard for researchers to use
them. In other words, most of the existing 3D visualization and computing APIs are low-level
(close to the hardware) and made for professional specialist developers.‚Äù &lt;a class="reference internal" href="../posts/2024/2024-05-28-week-0-robin.html#fury" id="id1"&gt;&lt;span&gt;[FURY]&lt;/span&gt;&lt;/a&gt;. FURY is our effort to bridge this gap with an easy-to-use API. With LLMs, the goal is to take this one step further and make it even simpler for people to get started. By reducing the barrier to entry, we can bring more people into this domain. Visualization should not be the most time-consuming thing for an engineer/researcher, it is supposed to just happen and help them accelerate faster.&lt;/p&gt;
&lt;section id="my-community-bonding-work"&gt;
&lt;h2&gt;My Community Bonding Work&lt;/h2&gt;
&lt;p&gt;The main goal for me was to try different hosting providers and LLMs, test everything and see how they perform. I had my final exams during this period so I lost around 2 weeks to that. But I did manage to catch up and finish the work.
We wanted to keep hosting cheap (preferably free). I‚Äôll detail all the things I tried and the review for each of them.&lt;/p&gt;
&lt;section id="hosting-work-in-order"&gt;
&lt;h3&gt;Hosting work, in order:&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ollama on Google Colab&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The way it works is by taking Ollama and running it inside google colab, then providing a reverse proxy using ngrok.
We later connect that reverse proxy to the local ollama instance.&lt;/p&gt;
&lt;p&gt;It works. But Google Colab can run only for a maximum of 12 hours and the runtimes will timeout if idle. Also, it was very hacky.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe width="640" height="390" src="https://drive.google.com/file/d/1qNLtXxAMlLQ8xO8jfV0keRtskvcsj-fC/preview" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ollama on Kaggle&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-05-28-week-0-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú2‚Äù (ordinal 2)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;Same as above, same issues. Talked with my mentor &lt;a class="reference external" href="https://github.com/m-agour"&gt;Mohamed&lt;/a&gt; and skipped implementation.&lt;/p&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;GGUF (GPT-Generated Unified Format) models with ctransformers on HuggingFace&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-05-28-week-0-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú3‚Äù (ordinal 3)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;The way it works is by taking a &lt;a class="reference external" href="https://vickiboykis.com/2024/02/28/gguf-the-long-way-around/"&gt;gguf&lt;/a&gt; model and then inferencing using the ctransformers library from HuggingFace. An endpoint will be exposed using flask/fastapi.&lt;/p&gt;
&lt;p&gt;It had issues like not all models were working, and ctransformers did not support all models. And the models that do work were slow on my machine. Local testing was a nightmare and inference speed on HuggingFace was also very slow.&lt;/p&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;GGUF models with llama-cpp-python, hosted on HuggingFace&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-05-28-week-0-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú4‚Äù (ordinal 4)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I used langchain wrapper over llama-cpp-python to inference GGUF models. This one was able to handle all GGUF models, and local testing was okayish. When I tried handling concurrent requests, it crashed and gave segmentation fault. I fixed segmentation fault later by increasing gunicorn workers (Gunicorn was the WSGI server I used).
It was still not that good and local testing was annoying me. I cannot iterate fast when it takes a full 2-3 minutes for the output to generate.&lt;/p&gt;
&lt;p&gt;This wrapper on a wrapper on a wrapper was also not fun (langchain wrapper of llama-cpp-python which itself is a wrapper of llama-cpp).&lt;/p&gt;
&lt;p&gt;I later removed langchain and reimplemented everything, but langchain wasn‚Äôt the reason for the slow performance so it wasn‚Äôt helpful.&lt;/p&gt;
&lt;ol class="arabic simple" start="5"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ollama on HuggingFace!&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-05-28-week-0-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: ‚Äú5‚Äù (ordinal 5)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;TLDR: This one worked!&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe width="640" height="390" src="https://drive.google.com/file/d/17yxdw169uqLlw6WKfi--bWEUQArJk7i2/preview" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;Ollama was perfect, it works like a charm on my machine and the ecosystem is also amazing (the people on their discord server are super kind). I knew I had to try ollama on HuggingFace.
I was unable to initially run ollama and provide an endpoint. My dockerfile builds were all failing. Later mentor &lt;a class="reference external" href="https://github.com/skoudoro/"&gt;Serge&lt;/a&gt; told me to use the official Ollama image (till then I was using the Ubuntu base image).&lt;/p&gt;
&lt;p&gt;I managed to get the dockerfile running locally, but still, the HuggingFace build was failing. Then I took help from HuggingFace community. They told me it was HuggingFace blocking some ports, so to try different ports. This is when I came across another ollama server repo, and it was using Ubuntu as the base image. I studied that code and modified my dockerfile. It was adding an env variable to repo settings that I missed. My current dockerfile is just 5 lines and it works well.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="fury-discord-bot"&gt;
&lt;h3&gt;FURY Discord Bot&lt;/h3&gt;
&lt;p&gt;I also made a barebones FURY Discord Bot which was connected to my local ollama instance. My dockerfile was stuck and I wanted to do something tangible, so I did this before the weekly meeting.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe src="https://drive.google.com/file/d/17aosa4iyDl90mYfVGPrmILtQdXtS6IEy/preview" width="640" height="480" allow="autoplay"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="what-is-coming-up-next-week"&gt;
&lt;h2&gt;What is coming up next week?&lt;/h2&gt;
&lt;p&gt;Currently, I‚Äôm finding a vector DB &amp;amp; studying how to effectively use RAG here.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="did-you-get-stuck-anywhere"&gt;
&lt;h2&gt;Did you get stuck anywhere?&lt;/h2&gt;
&lt;p&gt;Yes, I had some issues with the dockerfile. It was resolved.&lt;/p&gt;
&lt;p&gt;LINKS:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-bot/tree/main"&gt;HuggingFace repo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/robinroy03/fury-discord-bot"&gt;Discord Bot&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;div role="list" class="citation-list"&gt;
&lt;div class="citation" id="fury" role="doc-biblioentry"&gt;
&lt;span class="label"&gt;&lt;span class="fn-bracket"&gt;[&lt;/span&gt;&lt;a role="doc-backlink" href="#id1"&gt;FURY&lt;/a&gt;&lt;span class="fn-bracket"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;p&gt;Eleftherios Garyfallidis, Serge Koudoro, Javier Guaje, Marc-Alexandre C√¥t√©, Soham Biswas, David Reagan, Nasim Anousheh, Filipi Silva, Geoffrey Fox, and Fury Contributors. ‚ÄúFURY: advanced scientific visualization.‚Äù Journal of Open Source Software 6, no. 64 (2021): 3384. &lt;a class="reference external" href="https://doi.org/10.21105/joss.03384"&gt;https://doi.org/10.21105/joss.03384&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-05-28-week-0-robin.html"/>
    <summary>Hi, I‚Äôm Robin and I‚Äôm a 2nd year CS undergrad from Vellore Institute of Technology, Chennai. During GSoC ‚Äò24 my work will be to build an LLM chatbot which will help the community by answering their questions.</summary>
    <category term="google" label="google"/>
    <published>2024-05-29T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-05-28-first-post-wachiou-bouraima.html</id>
    <title>WEEK 0: The beginning of my journey in Google Summer of Code (GSoC) 2024</title>
    <updated>2024-05-28T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-0-the-beginning-of-my-journey-in-google-summer-of-code-gsoc-2024"&gt;

&lt;section id="here-we-go"&gt;
&lt;h2&gt;Here we go‚Ä¶..&lt;/h2&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Hello and welcome to my GSoC 24 journey, I‚Äôm Wachiou Bouraima pronounced (Wasiu Ibrahima).&lt;/div&gt;
&lt;div class="line"&gt;&lt;br /&gt;&lt;/div&gt;
&lt;div class="line"&gt;First of all, I‚Äôd like to express my deep gratitude for this immense opportunity.&lt;/div&gt;
&lt;div class="line"&gt;In this first article, yes you read ‚Äúfirst article‚Äù correctly, as it won‚Äôt be the only one, I‚Äôm going to share with you my first adventures in GSoC‚Äô24. Happy read&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section id="welcome-and-integration-into-the-community"&gt;
&lt;h2&gt;Welcome and integration into the community.&lt;/h2&gt;
&lt;p&gt;Like any good start, this week I have the incredible opportunity to be welcomed into the community by the Core Team and my Mentor himself, during this session the Mentors welcomed us warmly and also congratulated us. They shared with us the rules respected during and after the GSoC program. This session made me feel comfortable and confident.&lt;/p&gt;
&lt;p&gt;I also have to admit that the mentors are experienced and willing to share their knowledge, which I really appreciate. I also got to know the DIPY and FURY community members.&lt;/p&gt;
&lt;p&gt;Not only that, but I also attended the GSoC‚Äô24 summit organised by Google. This session was very informative and aimed to ease our way into GSoC‚Äô24, and help us avoid certain mistakes during and after the program.
I was able to meet the other GSoC students, and I must say that they are all very talented and motivated. I am very happy to be part of this community.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="project-details"&gt;
&lt;h2&gt;Project details&lt;/h2&gt;
&lt;p&gt;I will work on the project: &lt;strong&gt;Modernization of the FURY code base to improve readability, maintainability and performance&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This project aims to modernize the FURY code base by implementing keyword-only arguments to improve code clarity and explicit parameter passing. In addition, the integration of lazy loading functionality will optimize performance by loading resources only when they are needed. Finally, active participation in code refactoring efforts will improve the structure and maintainability of the FURY code base. The project will result in a modernized code base, comprehensive unit testing, updated Sphinx documentation and public presentations illustrating the improvements and benefits. Ultimately, the aim is to significantly improve the FURY code base for future developers and users.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="weekly-tasks"&gt;
&lt;h2&gt;Weekly tasks&lt;/h2&gt;
&lt;p&gt;I had to work on my first mission of the adventure, which was to create a decorator named &lt;strong&gt;keyword_only&lt;/strong&gt; to ensure that all arguments after the first are keyword arguments only. It also checks that all keyword arguments are expected by the function. You can check what I had to do in this Pull Request : &lt;a class="github reference external" href="https://github.com/fury-gl/fury/pull/888"&gt;fury-gl/fury#888&lt;/a&gt;. I‚Äôve learned a lot from implementing the &lt;strong&gt;keyword_only&lt;/strong&gt; decorator&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-s-next"&gt;
&lt;h2&gt;What‚Äôs next?&lt;/h2&gt;
&lt;p&gt;For my next task, I‚Äôll first apply the advice and comments from my first task, adding the &lt;strong&gt;keyword_only&lt;/strong&gt; decorator after all the necessary reviews and member approval, on all the functions concerned next, then I‚Äôll start and finish, integrating the lazy loading feature.&lt;/p&gt;
&lt;p&gt;ü•∞ Thank you for reading. Your comments are most welcome, and I learn from them.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-05-28-first-post-wachiou-bouraima.html"/>
    <summary>Like any good start, this week I have the incredible opportunity to be welcomed into the community by the Core Team and my Mentor himself, during this session the Mentors welcomed us warmly and also congratulated us. They shared with us the rules respected during and after the GSoC program. This session made me feel comfortable and confident.</summary>
    <category term="google" label="google"/>
    <published>2024-05-28T00:00:00+00:00</published>
  </entry>
</feed>
