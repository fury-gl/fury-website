<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://fury.gl/</id>
  <title>Blog - Posts in gsoc</title>
  <updated>2024-07-11T18:26:00.333402+00:00</updated>
  <link href="https://fury.gl/"/>
  <link href="https://fury.gl/blog/category/gsoc/atom.xml" rel="self"/>
  <generator uri="https://ablog.readthedocs.io/" version="0.11.10">ABlog</generator>
  <entry>
    <id>https://fury.gl/posts/2024/2024-07-06-week5-wachiou-bouraima.html</id>
    <title>WEEK 5: Implementing Lazy Loading in FURY with lazy_loader</title>
    <updated>2024-07-06T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-5-implementing-lazy-loading-in-fury-with-lazy-loader"&gt;

&lt;section id="hello-everyone"&gt;
&lt;h2&gt;Hello everyone,&lt;/h2&gt;
&lt;p&gt;Welcome back to my Google Summer of Code (GSoC) 2024 journey! This week has been particularly exciting as I introduced a significant performance optimization feature: lazy loading. Here’s an overview of my progress and contributions.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="introduction-of-lazy-loading"&gt;
&lt;h2&gt;&lt;strong&gt;Introduction of lazy loading&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;This week, I focused on implementing the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;lazy_loader&lt;/span&gt;&lt;/code&gt; feature of &lt;a class="reference external" href="https://scientific-python.org/"&gt;Scientific Python&lt;/a&gt; to optimize module loading in FURY. Lazy loading improves performance by deferring the loading of modules until they are actually needed, thus reducing start-up times and memory footprint.&lt;/p&gt;
&lt;p&gt;The implementation involved:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Implementation of Lazy Loading:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Application of lazy loading in several FURY modules using the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;lazy_loader&lt;/span&gt;&lt;/code&gt; module to improve performance&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;__init__.py&lt;/span&gt;&lt;/code&gt; files:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Modified &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;__init__.py&lt;/span&gt;&lt;/code&gt; files to support lazy loading where necessary. This ensures that modules are only loaded when they are accessed for the first time&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Added Type Stubs (&lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;__init__.pyi&lt;/span&gt;&lt;/code&gt;):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Adding type stubs (&lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;__init__.pyi&lt;/span&gt;&lt;/code&gt;) provides type hints for lazy-loading modules, improving code readability and maintainability&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Improved module organization:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Improved module organization in &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;__init__.py&lt;/span&gt;&lt;/code&gt; and &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;__init__.pyi&lt;/span&gt;&lt;/code&gt; files, to effectively support lazy loading.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
&lt;section id="example-implementation"&gt;
&lt;h2&gt;&lt;strong&gt;Example Implementation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;To give you an idea, here’s the actual implementation of how lazy loading was done using the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;lazy_loader&lt;/span&gt;&lt;/code&gt; module in FURY:&lt;/p&gt;
&lt;p&gt;&lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;__init__.py&lt;/span&gt;&lt;/code&gt; File:&lt;/p&gt;
&lt;div class="highlight-python notranslate"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;lazy_loader&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;lazy&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;fury.pkg_info&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;__version__&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pkg_commit_hash&lt;/span&gt;

&lt;span class="fm"&gt;__getattr__&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="fm"&gt;__dir__&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;__all__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lazy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attach_stub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="vm"&gt;__file__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;_all__&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;__version__&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;disable_warnings&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;enable_warnings&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;get_info&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# ... (functions)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;__init__.pyi&lt;/span&gt;&lt;/code&gt; File:&lt;/p&gt;
&lt;div class="highlight-python notranslate"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# This file is a stub type for the fury package. It provides information about types&lt;/span&gt;
&lt;span class="c1"&gt;# to help type-checking tools like mypy and improve the development experience&lt;/span&gt;
&lt;span class="c1"&gt;# with better autocompletion and documentation in code editors.&lt;/span&gt;

&lt;span class="n"&gt;__all__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;actor&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;actors&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;animation&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;colormap&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="c1"&gt;# ... (other modules)&lt;/span&gt;
    &lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;.&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;actor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;actors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;animation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;colormap&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="c1"&gt;# ... (other modules)&lt;/span&gt;
        &lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# ... (other functions)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;You can review the implementation in &lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/907/"&gt;this pull request&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="reading-spec1"&gt;
&lt;h2&gt;Reading &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;SPEC1&lt;/span&gt;&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;To align myself with best practice, I read the &lt;a class="reference external" href="https://scientific-python.org/specs/spec-0001/"&gt;SPEC1&lt;/a&gt; document available at Scientific Python SPEC1. This document provided valuable hints and guidelines that I took into account when implementing the lazy loading feature.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="did-i-get-stuck-anywhere"&gt;
&lt;h2&gt;Did I get stuck anywhere?&lt;/h2&gt;
&lt;p&gt;No, I didn’t encounter any major blockers this week. The implementation of lazy loading went smoothly, and I was able to complete the task.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-s-next"&gt;
&lt;h2&gt;&lt;strong&gt;What’s Next?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;For the next week, I plan to:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Review all my Pull Requests with my mentor &lt;a class="reference external" href="https://github.com/skoudoro/"&gt;Serge Koudoro&lt;/a&gt;, to ensure everything is up to FURY’s standards.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Start working on the redesign of the FURY website, making it more user-friendly and visually appealing.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Thank you for reading. Stay tuned for more updates on my progress!&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-07-06-week5-wachiou-bouraima.html"/>
    <summary>Welcome back to my Google Summer of Code (GSoC) 2024 journey! This week has been particularly exciting as I introduced a significant performance optimization feature: lazy loading. Here’s an overview of my progress and contributions.</summary>
    <category term="google" label="google"/>
    <published>2024-07-06T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-07-01-week-5-robin.html</id>
    <title>Week 5: LLM Benchmarking &amp; Architecture Modifications</title>
    <updated>2024-07-01T00:00:00+00:00</updated>
    <author>
      <name>Robin Roy</name>
    </author>
    <content type="html">&lt;section id="week-5-llm-benchmarking-architecture-modifications"&gt;

&lt;p&gt;Hi, I’m &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin&lt;/a&gt; and this is my blog about week 5.&lt;/p&gt;
&lt;p&gt;This week, we’ll take all the things we did in the previous weeks, and quantify them. Benchmarking an LLM is the process of grading the LLM answer. To grade properly, we need good rubrics, so that’s what I worked on this week. Also, I made some architectural changes, to make the overall development simple.&lt;/p&gt;
&lt;section id="things-i-did-in-week-5"&gt;
&lt;h2&gt;Things I did in Week 5&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Architectural Update&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Earlier, this was our architecture:&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;img src="https://github.com/fury-gl/fury-communication-assets/blob/main/gsoc_2024/7-6-2024-demo-architecture-gsoc-robin-week2.png?raw=true"&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;This had an obvious issue, all the core logic was inside the Discord Bot. So if I want to say, use the LLM inference for making a GitHub bot, or for benchmarking etc, it wasn’t possible. So I decided to cut the LLM logic from Discord Bot and made a new &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;LLM&lt;/span&gt; &lt;span class="pre"&gt;Router&lt;/span&gt;&lt;/code&gt;. It’ll handle all the LLM logic from now on, and we do not directly call any other endpoint other than this one.
It makes life simple, every input going into the endpoint goes like this:&lt;/p&gt;
&lt;div class="highlight-json notranslate"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;query&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Render a cube in fury&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;llm&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;llama3-70b-8192&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;knn&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;stream&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;False&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Every response coming out will be like this:&lt;/p&gt;
&lt;div class="highlight-json notranslate"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;response&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Yes, this is how it would be done python import fury....&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;references&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;1, 2, 3&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;dl class="simple"&gt;
&lt;dt&gt;What happens on the inside is completely abstracted away. You just call this and it’ll&lt;/dt&gt;&lt;dd&gt;&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;call the embedding model&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;pass embeddings to the database&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;return them to LLM (which you can choose)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;returns LLM answer with references to you&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Currently, we support &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;ollama&lt;/span&gt;&lt;/code&gt;, &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;google&lt;/span&gt;&lt;/code&gt; and &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;groq&lt;/span&gt;&lt;/code&gt; providers. That itself is 20+ LLM support, and you could swap between them using &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;/api/groq&lt;/span&gt; &lt;span class="pre"&gt;or&lt;/span&gt; &lt;span class="pre"&gt;api/google&lt;/span&gt; &lt;span class="pre"&gt;or&lt;/span&gt; &lt;span class="pre"&gt;/api/ollama&lt;/span&gt; &lt;span class="pre"&gt;...&lt;/span&gt;&lt;/code&gt;. Adding another provider is simply adding another endpoint.&lt;/p&gt;
&lt;p&gt;So if you do&lt;/p&gt;
&lt;p&gt;&lt;cite&gt;curl -X POST https://robinroy03-fury-engine.hf.space/api/groq/generate -H “Content-Type: application/json” -d ‘{“query”: “How do I create a sphere in FURY?”, “llm”: “llama3-70b-8192”, “knn”: “3”, “stream”: false}’&lt;/cite&gt;&lt;/p&gt;
&lt;p&gt;You’ll get a response from &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;llama3-70b-8192&lt;/span&gt;&lt;/code&gt; using &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;groq&lt;/span&gt;&lt;/code&gt;. If you do &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;https://robinroy03-fury-engine.hf.space/api/google/generate&lt;/span&gt;&lt;/code&gt; you can call any google gemini modes like &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;gemini-1.5-pro&lt;/span&gt;&lt;/code&gt; or &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;gemini-1.5-flash&lt;/span&gt;&lt;/code&gt;. Same for &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;ollama&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This still could be improved, it does not currently account for vision models. I did not add that because we do not use vision models other than for benchmarking now, and that too is done locally. Benchmarking could also be streamlined, I avoided that because benchmarking is still in development so I’ll have to rewrite every day. Presently you can use this core &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;router&lt;/span&gt;&lt;/code&gt; for a working LLM generation (you’ll get the same thing you’ll get from the Discord Bot. So if you have a website, all you have to do is call the API).&lt;/p&gt;
&lt;p&gt;This is our present architecture:&lt;/p&gt;
&lt;img alt="Present LLM architecture." src="https://fury.gl/_images/gsoc_llm_robin_week5.jpg" /&gt;
&lt;p&gt;It is the same thing as above, except we have two new components - &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;LLM&lt;/span&gt; &lt;span class="pre"&gt;Engine&lt;/span&gt;&lt;/code&gt; and a &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;Groq&lt;/span&gt; &lt;span class="pre"&gt;&amp;amp;&lt;/span&gt; &lt;span class="pre"&gt;Gemini&lt;/span&gt;&lt;/code&gt; endpoint. When we’ll end up having a conversational model setup (right now, it is one question and one answer), this model will be upgraded to accommodate that. My plan is to extend LLM Engine and add that. Other features such as vision also could be added to this as needed.&lt;/p&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Gemini Models added&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-5-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “2” (ordinal 2)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;As mentioned above, I added &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;Gemini&lt;/span&gt;&lt;/code&gt; models this week. They have a decent free tier. Also, I’m studying the feasibility of fine-tuning using the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;Gemini&lt;/span&gt;&lt;/code&gt; models.&lt;/p&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;LLM Benchmarking&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-5-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “3” (ordinal 3)&lt;/p&gt;
&lt;/aside&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: WARNING/2 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-5-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id1"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “this”.&lt;/p&gt;
&lt;/aside&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: WARNING/2 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-5-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id2"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “this”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;LLM Benchmarking is the process of evaluating the LLM output and giving a score. With this, making the model better will be simply a function of increasing the score. This area is still under development and the things I’ve tried here are the current standard procedures. To understand more about benchmarking, you can read &lt;a class="reference external" href="https://huggingface.co/learn/cookbook/en/rag_evaluation"&gt;this&lt;/a&gt;, &lt;a class="reference external" href="https://huggingface.co/learn/cookbook/en/llm_judge"&gt;this&lt;/a&gt; and &lt;a class="reference external" href="https://huggingface.co/learn/cookbook/en/advanced_rag"&gt;this&lt;/a&gt;. This &lt;a class="reference external" href="https://www.deeplearning.ai/short-courses/advanced-retrieval-for-ai/"&gt;course&lt;/a&gt; is also amazing.&lt;/p&gt;
&lt;p&gt;I’ll anyways give a TL;DR:
LLM benchmarking is essentially like writing an English Literature exam and getting the grades. Your evaluator may give you a 4 or a 5, and the reasoning can be varied. For the same answer, you may even get very varied results from 2 different evaluators! Two common rubrics they use are &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;groundedness&lt;/span&gt; &lt;span class="pre"&gt;(whether&lt;/span&gt; &lt;span class="pre"&gt;the&lt;/span&gt; &lt;span class="pre"&gt;answer&lt;/span&gt; &lt;span class="pre"&gt;follows&lt;/span&gt; &lt;span class="pre"&gt;from&lt;/span&gt; &lt;span class="pre"&gt;the&lt;/span&gt; &lt;span class="pre"&gt;material)&lt;/span&gt;&lt;/code&gt; and &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;completion&lt;/span&gt; &lt;span class="pre"&gt;(whether&lt;/span&gt; &lt;span class="pre"&gt;the&lt;/span&gt; &lt;span class="pre"&gt;answer&lt;/span&gt; &lt;span class="pre"&gt;is&lt;/span&gt; &lt;span class="pre"&gt;complete,&lt;/span&gt; &lt;span class="pre"&gt;whether&lt;/span&gt; &lt;span class="pre"&gt;it&lt;/span&gt; &lt;span class="pre"&gt;fully&lt;/span&gt; &lt;span class="pre"&gt;answers&lt;/span&gt; &lt;span class="pre"&gt;the&lt;/span&gt; &lt;span class="pre"&gt;question&lt;/span&gt; &lt;span class="pre"&gt;with&lt;/span&gt; &lt;span class="pre"&gt;respect&lt;/span&gt; &lt;span class="pre"&gt;to&lt;/span&gt; &lt;span class="pre"&gt;the&lt;/span&gt; &lt;span class="pre"&gt;material)&lt;/span&gt;&lt;/code&gt;. These are the same rubrics we’ll use for LLM evaluation. For code, it’s different. The code should compile and do exactly what it should.&lt;/p&gt;
&lt;p&gt;Now FURY Bot does 2 things - writing code &amp;amp; writing answers for common questions (on GitHub issues etc). Presently, I’ve only collected data for coding questions, as they are much easier to evaluate and give a clear sense of direction (also I found more coding data).&lt;/p&gt;
&lt;dl class="simple"&gt;
&lt;dt&gt;Evaluating FURY code can be done by:&lt;/dt&gt;&lt;dd&gt;&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Running the code.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Checking the output.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Now we do this using &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;pytest&lt;/span&gt;&lt;/code&gt; in the FURY repo for tests. But this approach is tedious, as collecting questions and writing test cases take a lot of time, also the orientation of the 3D objects also matters (an LLM generation is not deterministic). So we are using a vision model &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;moondream2&lt;/span&gt;&lt;/code&gt; to check the LLM generated output and verify if it is what we actually wanted.
On a high level, this is what we do (for now):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Take a QnA pair from the collected dataset (I’ve collected ~23 questions).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ask the LLM to generate a FURY code for that (using the references).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run this generated code.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Check the output using &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;moondream2&lt;/span&gt;&lt;/code&gt; and verify whether it is what we wanted.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is also &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;fast_eval&lt;/span&gt;&lt;/code&gt; which checks whether the code compiles and skips &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;moondream2&lt;/span&gt;&lt;/code&gt; entirely. This is obviously faster and is also decently good (is actually a pretty good heuristic). If it runs, assume it works :)&lt;/p&gt;
&lt;p&gt;This is our current stats: (from now on, we can finally talk using numbers)&lt;/p&gt;
&lt;section id="coding-benchmark"&gt;
&lt;h3&gt;Coding benchmark:&lt;/h3&gt;
&lt;p&gt;On &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;fast_eval&lt;/span&gt;&lt;/code&gt; we have a success rate of &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;47.83%&lt;/span&gt;&lt;/code&gt; for &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;groq&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;On &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;normal_eval&lt;/span&gt;&lt;/code&gt; we have a success rate of &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;13.04%&lt;/span&gt;&lt;/code&gt; for &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;groq&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note that &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;moondream2&lt;/span&gt;&lt;/code&gt; also sometimes mistakes the output for something else. It is close to &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;~45%&lt;/span&gt;&lt;/code&gt; when I checked manually. For now, I’m only going to focus on &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;fast_eval&lt;/span&gt;&lt;/code&gt; as fixing &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;moondream2&lt;/span&gt;&lt;/code&gt; is a distraction for the moment. (This actually gets very meta, there are projects where they have benchmarks for the evaluator and so on. &lt;a class="reference external" href="https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/"&gt;Read this&lt;/a&gt;.)&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="what-is-coming-up-next-week"&gt;
&lt;h2&gt;What is coming up next week?&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Better benchmark scores :)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Line number highlighting &amp;#64; references.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Some &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;references&lt;/span&gt;&lt;/code&gt; improvements.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="did-you-get-stuck-anywhere"&gt;
&lt;h2&gt;Did you get stuck anywhere?&lt;/h2&gt;
&lt;p&gt;No, I did not get stuck anywhere.&lt;/p&gt;
&lt;p&gt;LINKS:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/learn/cookbook/en/rag_evaluation"&gt;RAG Evaluation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/learn/cookbook/en/llm_judge"&gt;LLM Judge&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/learn/cookbook/en/advanced_rag"&gt;Advanced RAG&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://www.deeplearning.ai/short-courses/advanced-retrieval-for-ai/"&gt;Advanced Retrieval for AI&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/vikhyatk/moondream2"&gt;Moondream2&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/"&gt;Finding GPT-4 mistakes with GPT-4&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-07-01-week-5-robin.html"/>
    <summary>Hi, I’m Robin and this is my blog about week 5.</summary>
    <category term="google" label="google"/>
    <published>2024-07-01T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-07-01-week-4-robin.html</id>
    <title>Week 4: Pipeline Improvements and Taking The Bot Public!</title>
    <updated>2024-07-01T00:00:00+00:00</updated>
    <author>
      <name>Robin Roy</name>
    </author>
    <content type="html">&lt;section id="week-4-pipeline-improvements-and-taking-the-bot-public"&gt;

&lt;p&gt;Hi, I’m &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin&lt;/a&gt; and this is my blog about week 4.&lt;/p&gt;
&lt;p&gt;My goals for week 4 were to move my Google colab notes to a proper Python script, improve the existing code, and make a working pipeline to upsert data easily. Also, the bot is public now :) Anyone reading this blog could join this &lt;a class="reference external" href="https://discord.gg/NVkE6Qd2bZ"&gt;Discord Server&lt;/a&gt; and ask questions right away!&lt;/p&gt;
&lt;section id="things-i-did-in-week-4"&gt;
&lt;h2&gt;Things I did in Week 4&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Chunking tutorials and documentation&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Earlier, only files fitting the context window of the embedding model were upserted. This was because otherwise, we’d have to split the file in half and lose the overall context. This will lead to information loss and retrieval will be messy. Now, I decided I’d upsert everything by splitting information properly. By “properly”, what I mean is it won’t be a random split, and there’ll be logical reasoning behind every chunk.&lt;/p&gt;
&lt;p&gt;This area is still actively studied, and the whole concept is to find ideal chunks which are self-sufficient and contain the most information. This &lt;a class="reference external" href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb"&gt;notebook&lt;/a&gt; details 6 different approaches, I read through them and some of their associated literature and decided we’ll use &lt;cite&gt;Recursive Character Text Splitting&lt;/cite&gt; and &lt;cite&gt;Document Specific Splitting&lt;/cite&gt; for now. There is no major reason for this, I just felt it’ll work well for now (a reasoning-backed approach will come in a few weeks). There is a lot of experimentation we could do here, a better chunking will result in better &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;references&lt;/span&gt;&lt;/code&gt; generation and so on.&lt;/p&gt;
&lt;dl class="simple"&gt;
&lt;dt&gt;So this is our current process&lt;/dt&gt;&lt;dd&gt;&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;if normal function/class definition: no splitting, chunk as it is.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;if rst files, use the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;rst&lt;/span&gt; &lt;span class="pre"&gt;parser&lt;/span&gt;&lt;/code&gt; and split them with a chunk size of ~8000 tokens (max llama could take). RST files in FURY contain documentation &amp;amp; blog posts.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;if tutorial, try chunking as it is, if not possible split at 8000 tokens.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Function/class definitions are generally under 8000 so I’ve not done explicit checks for now, the model will trim the remaining if longer (I found some long classes later).&lt;/p&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Move colab files to a proper Python script&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-4-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “2” (ordinal 2)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I did all the upsertion and experiments on colab. It is messy and can’t be used in production. We need a one-click approach to upsertion. Something like point to &lt;cite&gt;fury&lt;/cite&gt; directory and it should do everything. So I took the messy colab code and made a python script from it.&lt;/p&gt;
&lt;p&gt;One of my key goals is to separate core application logic from LLMs/Database providers. We should be able to swap them as needed without much fuss. I’ll talk more about this in week 5.&lt;/p&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Taking the bot public!&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-4-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “3” (ordinal 3)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;The whole point of making the bot is to help improve the productivity of FURY developers. So I decided to take it public on &lt;a class="reference external" href="https://discord.gg/NVkE6Qd2bZ"&gt;this discord server&lt;/a&gt;. You could use it today! (actually, you could’ve used it from the 20th of last month, this blog got delayed😢)&lt;/p&gt;
&lt;p&gt;I’ll observe what people are asking and then iterate towards making the bot better in that area. I think it’ll be better than making the bot good on what I believe is the best.&lt;/p&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Minor bugfixes and stuff&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-4-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “4” (ordinal 4)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;Did some minor bug fixes on things like the Discord bot generation cutoff and error handling improvements. It was Discord message limit (&amp;lt;=2000) that caused the generation to cut off, I split the message into parts to fix that. Error handling was improved generally everywhere. I’ll need to bring logging later.&lt;/p&gt;
&lt;section id="minor-sidequest"&gt;
&lt;h3&gt;Minor Sidequest&lt;/h3&gt;
&lt;p&gt;This is in no way related to FURY, but it was fun so I thought I’d add it here :)&lt;/p&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: WARNING/2 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-4-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id1"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “link”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;So after midterms, I decided to go back home, to maximally use my time I searched for things to do and found a local FOSS event (&lt;a class="reference external" href="https://x.com/FOSSUnitedKochi/status/1804763181274759645"&gt;link&lt;/a&gt;). It was done by FOSS United Kochi and it’s one of the major FOSS events in my state (Kerala, India). Met some Pythonistas! Explained what FURY is to them. I also ended up finding some lore (&lt;a class="reference external" href="https://www.gnu.org/education/edu-system-india.html"&gt;link&lt;/a&gt;) about how GNU/Linux spread in Kerala, India. Also found some old FOSS event pictures (&lt;a class="reference external" href="https://www.flickr.com/photos/pce/245170427/in/photostream/"&gt;this&lt;/a&gt; one is talking about Python, 2003 World of Python). This was my first FOSS event outside campus so it was fun :)&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="what-is-coming-up-next-week"&gt;
&lt;h2&gt;What is coming up next week?&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Benchmarking&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Architecture Update&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="did-you-get-stuck-anywhere"&gt;
&lt;h2&gt;Did you get stuck anywhere?&lt;/h2&gt;
&lt;p&gt;No, I did not get stuck. This week was more of learning and experimentation so I think it’s normal what I encountered.&lt;/p&gt;
&lt;p&gt;LINKS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-07-01-week-4-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id2"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “discord server”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://discord.gg/NVkE6Qd2bZ"&gt;Discord Server&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb"&gt;A Text Splitting Guide&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://www.gnu.org/education/edu-system-india.html"&gt;GNU Case of Kerala&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://www.flickr.com/photos/pce/245170427/in/photostream/"&gt;2003 World of Python&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://x.com/FOSSUnitedKochi/status/1804763181274759645"&gt;FOSS United Kochi&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin :)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-07-01-week-4-robin.html"/>
    <summary>Hi, I’m Robin and this is my blog about week 4.</summary>
    <category term="google" label="google"/>
    <published>2024-07-01T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-26-week4-wachiou-bouraima.html</id>
    <title>WEEK 4: Updating Decorator, Exploring Lazy Loading, and Code Reviews</title>
    <updated>2024-06-26T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-4-updating-decorator-exploring-lazy-loading-and-code-reviews"&gt;

&lt;section id="hello-everyone"&gt;
&lt;h2&gt;Hello everyone,&lt;/h2&gt;
&lt;p&gt;Welcome again to my Google summer of code 2024 (GSoC’ 2024) journey 2024!.
This week, I focused on updating the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator, applying it across multiple modules, exploring lazy loading, and continuing with code reviews.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="updating-the-warn-on-args-to-kwargs-decorator"&gt;
&lt;h2&gt;Updating the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator&lt;/h2&gt;
&lt;p&gt;Based on feedback from my mentor &lt;a class="reference external" href="https://github.com/skoudoro"&gt;Serge Koudoro&lt;/a&gt;  and peers  &lt;a class="reference external" href="https://github.com/itellaetxe"&gt;Iñigo Tellaetxe Elorriaga&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin Roy&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka&lt;/a&gt;, I refined the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator and its associated unit tests:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Improvements:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Added conditions to verify if the values of &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;from_version&lt;/span&gt;&lt;/code&gt;, &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;until_version&lt;/span&gt;&lt;/code&gt;, and the current version of FURY are respected. This includes handling cases where &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;from_version&lt;/span&gt;&lt;/code&gt; is greater than the current version of FURY, &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;until_version&lt;/span&gt;&lt;/code&gt; is less than the current version of FURY, and &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;until_version&lt;/span&gt;&lt;/code&gt; is greater than or equal to the current version of FURY.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensured the decorator and tests cover a broader range of edge cases.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Enhanced the warning messages for better clarity and guidance.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Doctest Updates:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Updated the doctest considering the values of &lt;cite&gt;from_version&lt;/cite&gt; and &lt;cite&gt;until_version&lt;/cite&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Moved the doctest from the &lt;cite&gt;def decorator()&lt;/cite&gt; function to the root function.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unit Tests:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight-python notranslate"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test_warn_on_args_to_kwargs&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="nd"&gt;@warn_on_args_to_kwargs&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;

&lt;span class="c1"&gt;# if FURY_CURRENT_VERSION is less than from_version&lt;/span&gt;
&lt;span class="n"&gt;fury&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;0.0.0&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;npt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assert_equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;npt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assert_equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;npt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;assert_raises&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ne"&gt;TypeError&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;This ensures robust validation and helps catch potential issues early.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="applying-the-warn-on-args-to-kwargs-decorator"&gt;
&lt;h2&gt;Applying the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; Decorator&lt;/h2&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: WARNING/2 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-26-week4-wachiou-bouraima.rst&lt;/span&gt;, line 51)&lt;/p&gt;
&lt;p&gt;Title underline too short.&lt;/p&gt;
&lt;div class="highlight-default notranslate"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Applying the ``warn_on_args_to_kwargs`` Decorator
-----------------------------------------------
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/aside&gt;
&lt;p&gt;This week, I applied the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator to several modules, ensuring consistent usage and improved code quality. The modules updated include:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;actors&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;ui&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;animation&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;shares&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;data&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For each module, I opened a pull request to track the changes and facilitate reviews:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;actors&lt;/cite&gt;: &lt;a class="github reference external" href="https://github.com/fury-gl/fury/pull/898"&gt;fury-gl/fury#898&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;animation&lt;/cite&gt;: &lt;a class="github reference external" href="https://github.com/fury-gl/fury/pull/899"&gt;fury-gl/fury#899&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;data&lt;/cite&gt;: &lt;a class="github reference external" href="https://github.com/fury-gl/fury/pull/900"&gt;fury-gl/fury#900&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;shares&lt;/cite&gt;: &lt;a class="github reference external" href="https://github.com/fury-gl/fury/pull/901"&gt;fury-gl/fury#901&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;ui&lt;/cite&gt;: &lt;a class="github reference external" href="https://github.com/fury-gl/fury/pull/902"&gt;fury-gl/fury#902&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="exploring-lazy-loading"&gt;
&lt;h2&gt;Exploring lazy loading&lt;/h2&gt;
&lt;p&gt;In order to optimize performance, I’ve started exploring and implementing lazy loading. This week, the focus was on the following points:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Getting to grips with how the lazy loader works&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Implementing some small script to understand how the lazy loader works&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I also read the SPEC1 document available at &lt;a class="reference external" href="https://scientific-python.org/specs/spec-0001/"&gt;SPEC1&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Understanding the benefits of lazy loading and how it can be applied to the FURY code base&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Planning the integration of lazy loading into the FURY code base&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Code sample: &lt;a class="reference external" href="https://gist.github.com/WassCodeur/98297d7a59b27979d27945760e3ffb10"&gt;https://gist.github.com/WassCodeur/98297d7a59b27979d27945760e3ffb10&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;section id="peer-code-review"&gt;
&lt;h2&gt;Peer Code Review&lt;/h2&gt;
&lt;p&gt;This week, I continued to dedicate time to reviewing the code of my peers. Specifically, I reviewed Kaustav Deka’s work, providing constructive feedback and suggestions for improvement. You can view the pull request here: &lt;a class="github reference external" href="https://github.com/dipy/dipy/pull/3239"&gt;dipy/dipy#3239&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="acknowledgements"&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-26-week4-wachiou-bouraima.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id1"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “iñigo tellaetxe elorriaga”.&lt;/p&gt;
&lt;/aside&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-26-week4-wachiou-bouraima.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id2"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “robin roy”.&lt;/p&gt;
&lt;/aside&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-26-week4-wachiou-bouraima.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id3"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “kaustav deka”.&lt;/p&gt;
&lt;/aside&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-26-week4-wachiou-bouraima.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id4"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “serge koudoro”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I am deeply grateful to my classmates &lt;a class="reference external" href="https://github.com/itellaetxe"&gt;Iñigo Tellaetxe Elorriaga&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin Roy&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka&lt;/a&gt;  for their continuous support and insightful suggestions. Special thanks to my mentor, &lt;a class="reference external" href="https://github.com/skoudoro"&gt;Serge Koudoro&lt;/a&gt; , whose expertise and guidance have been invaluable in navigating these technical challenges.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="did-i-get-stuck"&gt;
&lt;h2&gt;Did I get stuck?&lt;/h2&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-26-week4-wachiou-bouraima.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id5"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “serge koudoro”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;Yes, I was a bit confused about understanding lazy loader, but thanks to the help of my mentor &lt;a class="reference external" href="https://github.com/skoudoro"&gt;Serge Koudoro&lt;/a&gt; , I was able to understand it better.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-s-next"&gt;
&lt;h2&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;For the upcoming week, I plan to:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Implement lazy loading in the FURY code base&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Continue refining the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator based on feedback&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Engage in more code reviews to support my peers&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Prepare to working on the FURY website to improve the documentation and user experience&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for following my progress. Your feedback is always welcome.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-26-week4-wachiou-bouraima.html"/>
    <summary>Welcome again to my Google summer of code 2024 (GSoC’ 2024) journey 2024!.
This week, I focused on updating the warn_on_args_to_kwargs decorator, applying it across multiple modules, exploring lazy loading, and continuing with code reviews.</summary>
    <category term="google" label="google"/>
    <published>2024-06-26T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-26-week3-wachiou-bouraima.html</id>
    <title>WEEK 3: Refinements and Further Enhancements</title>
    <updated>2024-06-26T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-3-refinements-and-further-enhancements"&gt;

&lt;section id="hello-everyone"&gt;
&lt;h2&gt;Hello everyone,&lt;/h2&gt;
&lt;p&gt;Welcome to the fourth week of my Google Summer of Code (GSoC) 2024 journey!
This week I’ve been delving into the technical aspects of my project,
focusing on the consistent application of the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator and the initial implementation of lazy loading.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="consistent-application-of-warn-on-args-to-kwargs"&gt;
&lt;h2&gt;Consistent application of &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;This week I continued to apply the decorator to functions.
To ensure consistency across the code base, I audited all functions that could benefit from the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator.
To do this, I had to:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Identify target functions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Identify functions that could benefit from the decorator.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;continue reviewing the code base to identify functions that accept both positional and keyword arguments.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Applying the Decorator:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;For each identified function, I added the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight-python notranslate"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nd"&gt;@warn_on_args_to_kwargs&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_actor_from_primitive&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
   &lt;span class="n"&gt;vertices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   &lt;span class="n"&gt;triangles&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   &lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   &lt;span class="n"&gt;normals&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   &lt;span class="n"&gt;backface_culling&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   &lt;span class="n"&gt;prim_count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   &lt;span class="p"&gt;):&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;&lt;p&gt;Updating Unit Tests:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-26-week3-wachiou-bouraima.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “3” (ordinal 3)&lt;/p&gt;
&lt;/aside&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;updated all the unit tests for the functions where the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator is applied to ensure they respect the new format.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight-python notranslate"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;actr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_actor_from_primitive&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;big_verts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big_faces&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;big_colors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;You can find more details and the implementation in my pull request: &lt;a class="github reference external" href="https://github.com/fury-gl/fury/pull/888"&gt;fury-gl/fury#888&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="what-happens-next"&gt;
&lt;h2&gt;What Happens Next?&lt;/h2&gt;
&lt;p&gt;For week 4, I plan to:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Continue refining the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator based on feedback from my Peers &lt;a class="reference external" href="https://github.com/itellaetxe"&gt;Iñigo Tellaetxe Elorriaga&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin Roy&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka&lt;/a&gt;, my guide: &lt;a class="reference external" href="https://github.com/skoudoro"&gt;Serge Koudoro&lt;/a&gt; and the other community members.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Apply the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator to all the remaining modules and update all the unit tests of these modules too, to respect the desired format.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Dive deep into the lazy loading functionality based on my research to optimize performance.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Further engage in code reviews to support my peers and improve our project.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="did-i-get-stuck"&gt;
&lt;h2&gt;Did I get stuck?&lt;/h2&gt;
&lt;p&gt;I didn’t get stuck.&lt;/p&gt;
&lt;p&gt;Thank you for following my progress. Your feedback is always welcome.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-26-week3-wachiou-bouraima.html"/>
    <summary>Welcome to the fourth week of my Google Summer of Code (GSoC) 2024 journey!
This week I’ve been delving into the technical aspects of my project,
focusing on the consistent application of the warn_on_args_to_kwargs decorator and the initial implementation of lazy loading.</summary>
    <category term="google" label="google"/>
    <published>2024-06-26T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-16-week3-robin.html</id>
    <title>Week 3: Data Data Data!</title>
    <updated>2024-06-16T00:00:00+00:00</updated>
    <author>
      <name>Robin Roy</name>
    </author>
    <content type="html">&lt;section id="week-3-data-data-data"&gt;

&lt;p&gt;Hi, I’m &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin&lt;/a&gt; and this is my blog about week 3.&lt;/p&gt;
&lt;p&gt;My goal for week 3 was to collect data more efficiently and improve the citations. I also had my mid-terms during this week so I had to get things done fast.&lt;/p&gt;
&lt;section id="things-i-did-in-week-3"&gt;
&lt;h2&gt;Things I did in week 3&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A better data parsing technique&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;My initial approach was naive, it was just regex and some common filtrations. Later, my mentors told me to use the &lt;cite&gt;inspect&lt;/cite&gt; module. I studied that module and realized that I needed to parse data using an AST. I didn’t use the &lt;cite&gt;inspect&lt;/cite&gt; module to do the parsing, since I only had to get the function/class signature and docstrings. So instead I used the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;ast&lt;/span&gt;&lt;/code&gt; module from python stdlib. My mentors gave me the general direction to go through - which was using ASTs to parse data effectively.&lt;/p&gt;
&lt;p&gt;So now we have a script which you run like &lt;cite&gt;python extractor.py fury&lt;/cite&gt; and it’ll generate the appropriate JSON files.&lt;/p&gt;
&lt;p&gt;&lt;cite&gt;{“path”: “../..”, “function/class name”: “name”, “docstring”: “..”, “class_methods”: [“method1”, “…”]}&lt;/cite&gt;&lt;/p&gt;
&lt;p&gt;I also changed the upserting chunk format. Earlier it was just strings, now it is JSON (same thing above). I do not have a scientific reason for this, but empirically it looks like it helped. Benchmarking is something I’m planning to do next week.&lt;/p&gt;
&lt;p&gt;Metadata format:&lt;/p&gt;
&lt;p&gt;&lt;cite&gt;metadata: {“path”: “../..”, “function/class name”: “name”, “docstring”: “..”, “methods”: [(method1, docstring), (method2, docstring), …]}&lt;/cite&gt;&lt;/p&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Links for citation&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-16-week3-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “2” (ordinal 2)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;Now the bot shows links for citations. Because of the new parsing, I was able to do that pretty efficiently.&lt;/p&gt;
&lt;img alt="Link based references for the LLM output." src="https://fury.gl/_images/gsoc-robin-3-fury-discord-bot-references-url.jpg" /&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Faster Inference&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-16-week3-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “3” (ordinal 3)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;So this is something about the Generative AI field. There are too many things happening you might miss some stuff. &lt;cite&gt;Groq&lt;/cite&gt; is a company providing free APIs for the llama and other opensource models (free for now, at least). Its inference speed is also super high. So I decided to integrate that also into our infrastructure.
Since everything is a microservice in our architecture, it is easy to add new things.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;Our architecture:&lt;/dt&gt;&lt;dd&gt;&lt;img src="https://github.com/fury-gl/fury-communication-assets/blob/main/gsoc_2024/7-6-2024-demo-architecture-gsoc-robin-week2.png?raw=true"&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;So now, along with Ollama, we have Groq inference also. I aim to make a &lt;cite&gt;router&lt;/cite&gt; so that we can swap different providers as required. I’m also very interested in integrating Google Gemini 1.5 Flash and other models. Groq does not support fine-tuning, but Flash supports it and is &lt;a class="reference external" href="https://developers.googleblog.com/en/gemini-15-pro-and-15-flash-now-available/#:~:text=To%20support%20that%2C%20we%20will%20also%20be%20rolling%20out%20tuning%20support%20for%20Gemini%201.5%20Flash%20on%20June%2017th.%20Tuning%20will%20be%20supported%20in%20both%20Google%20AI%20Studio%20and%20the%20Gemini%20API%20directly.%20Currently%2C%20tuning%20jobs%20are%20free%20of%20charge%2C%20and%20using%20a%20tuned%20model%20does%20not%20incur%20any%20additional%20per%2Dtoken%20costs."&gt;free of cost&lt;/a&gt; (for now). Our architecture is platform agnostic, so we can try out different things without being locked into any of them. We will also fine-tune our phi3 model since we have the data with us.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe src="https://github.com/robinroy03/fury-discord-bot/assets/115863770/234fee85-9eb4-4fd5-a334-9e6d11e552a3" width="640" height="390" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Dockerizing Discord Bot&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-16-week3-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “4” (ordinal 4)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I earlier used the huggingface implementation (copied their implementation demo). It was bad. My mentors suggested to dockerize the bot so I did that.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-is-coming-up-next-week"&gt;
&lt;h2&gt;What is coming up next week?&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Benchmarking. Now we have the data, but we need to properly benchmark to see whether the modifications I make every day are making the bot dumber or smarter.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Study different techniques to improve model answer accuracy such as &lt;a class="reference external" href="https://arxiv.org/abs/2212.10496"&gt;HyDE&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Study how to go forward with fine-tuning.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Improved references.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Collect more data.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="did-you-get-stuck-anywhere"&gt;
&lt;h2&gt;Did you get stuck anywhere?&lt;/h2&gt;
&lt;p&gt;No, everything went well this week. Exam preparation was a pain though😢.&lt;/p&gt;
&lt;p&gt;LINKS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://developers.googleblog.com/en/gemini-15-pro-and-15-flash-now-available"&gt;Gemini Blog&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-16-week3-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id1"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “hyde”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://arxiv.org/abs/2212.10496"&gt;HyDE&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin :)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-16-week3-robin.html"/>
    <summary>Hi, I’m Robin and this is my blog about week 3.</summary>
    <category term="google" label="google"/>
    <published>2024-06-16T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-16-week2-robin.html</id>
    <title>Week 2: The first iteration!</title>
    <updated>2024-06-16T00:00:00+00:00</updated>
    <author>
      <name>Robin Roy</name>
    </author>
    <content type="html">&lt;section id="week-2-the-first-iteration"&gt;

&lt;p&gt;Hi, I’m &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin&lt;/a&gt; and this is my blog about week 2.&lt;/p&gt;
&lt;p&gt;My goal for week 2 was to connect everything and make a prototype. So now we have a bot working 24x7 to answer all your doubts :)&lt;/p&gt;
&lt;dl class="simple"&gt;
&lt;dt&gt;Apart from the things mentioned in my &lt;a class="reference external" href="https://fury.gl/latest/posts/2024/2024-06-06-week-1-robin.html"&gt;week 1 blog&lt;/a&gt;, the things I did in week 2 are basically:&lt;/dt&gt;&lt;dd&gt;&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Chunking the files for embedding.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Upserting the chunks into the database.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Connecting everything together.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Making the discord bot async.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Merging a PR.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;section id="chunking-the-files-for-embedding"&gt;
&lt;h2&gt;1) &lt;strong&gt;Chunking the files for embedding&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;In the context of building LLM-related applications, chunking is the process of breaking down large pieces of text into smaller segments. It’s an essential technique that helps optimize the relevance of the content we get back from a vector database once we use an embedding model to embed content. For our case with FURY, our data is entirely code. So one approach I tried was to take docstrings and the function/class signature.&lt;/p&gt;
&lt;p&gt;I used a naive parser during week 2, which used a combination of regex and common pattern matching to do this splitting. Later my mentors &lt;a class="reference external" href="https://github.com/m-agour"&gt;Mohamed&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/skoudoro/"&gt;Serge&lt;/a&gt; told me to use a better approach, using the python &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;inspect&lt;/span&gt;&lt;/code&gt; module.&lt;/p&gt;
&lt;p&gt;Another thing to consider was the chunk size. It is shown that smaller chunks outperform larger chunks. This can be intuitively thought of like this: An embedding model can compress a smaller text to 1024 vectors without much data loss compared to compressing a larger text to 1024 vectors.&lt;/p&gt;
&lt;p&gt;This also introduces another important issue, we need a way to test it based on our model. So we need benchmarking.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="upserting-chunks-into-the-database"&gt;
&lt;h2&gt;2) &lt;strong&gt;Upserting chunks into the database&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;I upserted all the chunks into the database, along with the vectors I gave metadata which was the function signature and docstrings. Later in week 3, we’ll modify this to show links instead of the big wall of text.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="connecting-everything-together"&gt;
&lt;h2&gt;3) &lt;strong&gt;Connecting everything together&lt;/strong&gt;&lt;/h2&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-16-week2-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id1"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “week 1 blog”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I took the 4 key parts - Discord Bot, LLM API, Embeddings API and the Database API and connected them together. This was explained on the &lt;a class="reference external" href="https://fury.gl/latest/posts/2024/2024-06-06-week-1-robin.html"&gt;week 1 blog&lt;/a&gt; itself.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="making-the-discord-bot-async"&gt;
&lt;h2&gt;4) &lt;strong&gt;Making the Discord Bot async&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;One of the biggest challenges I faced this week was to get everything running properly. LLM output takes a lot of time to generate (we’ll fix this amazingly well in week 3 BTW).
I made a big mistake, I used &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;requests&lt;/span&gt;&lt;/code&gt; library to do the REST API calls. It occurred to me later that it is synchronous and does blocking calls. This was the reason my Discord bot was dying randomly. I fixed it by migrating to &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;aiohttp&lt;/span&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This also made me realize I can use async in a lot of other places. A lot of these tasks are I/O bound. If I make them async we might be able to take many more concurrent requests.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="merging-a-pr"&gt;
&lt;h2&gt;5) &lt;strong&gt;Merging a PR&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;I merged a &lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/893"&gt;PR&lt;/a&gt; which modifies &lt;cite&gt;.gitignore&lt;/cite&gt;. I found this while generating the Sphinx docs.&lt;/p&gt;
&lt;section id="what-is-coming-up-next-week"&gt;
&lt;h3&gt;What is coming up next week?&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;A faster LLM inference.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Better pipeline for data collection.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Links for citation.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="did-you-get-stuck-anywhere"&gt;
&lt;h3&gt;Did you get stuck anywhere?&lt;/h3&gt;
&lt;p&gt;Took me some time to realize I was using synchronous code inside async. Fixed it later.&lt;/p&gt;
&lt;p&gt;LINKS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-16-week2-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id2"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “week 1 blog”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://fury.gl/latest/posts/2024/2024-06-06-week-1-robin.html"&gt;Week 1 Blog&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-16-week2-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id3"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “pr”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/893"&gt;PR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/skoudoro/"&gt;Serge Koudoro&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/m-agour"&gt;Mohamed Abouagour&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin :)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-16-week2-robin.html"/>
    <summary>Hi, I’m Robin and this is my blog about week 2.</summary>
    <category term="google" label="google"/>
    <published>2024-06-16T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-15-week2-wachiou-bouraima.html</id>
    <title>WEEK 2: Refinements and Further Enhancements</title>
    <updated>2024-06-15T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-2-refinements-and-further-enhancements"&gt;

&lt;section id="hello-again"&gt;
&lt;h2&gt;Hello again,&lt;/h2&gt;
&lt;p&gt;Welcome back to my Google Summer of Code (GSoC) 2024 journey! This week has been dedicated to refining and improving the work done so far, with a particular focus on the keyword_only decorator.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="renaming-and-updating-the-decorator"&gt;
&lt;h2&gt;Renaming and Updating the Decorator&lt;/h2&gt;
&lt;p&gt;This week, I’ve updated &lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/888"&gt;this Pull Request&lt;/a&gt; by renaming the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;keyword_only&lt;/span&gt;&lt;/code&gt; decorator to &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; for greater clarity. The updated decorator now includes version parameters from_version and until_version. This enhancement ensures that the decorator will raise a RuntimeError if the current version of FURY is greater than until_version.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="peer-code-review"&gt;
&lt;h2&gt;Peer Code Review&lt;/h2&gt;
&lt;p&gt;I also spent time reviewing &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka’s&lt;/a&gt; code. This exercise remains rewarding, as it helps me understand different coding styles and approaches. Constructive feedback and suggestions from my classmates were invaluable, not only in helping my teammates but also in improving my own coding and reviewing skills.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="research-into-lazy-loading"&gt;
&lt;h2&gt;Research into lazy loading&lt;/h2&gt;
&lt;p&gt;In parallel, I started researching the lazy loading feature and thinking about how to implement it. This feature will optimize performance by loading resources only when they’re needed, which is crucial to improving the efficiency of FURY’s code base.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="acknowledgements"&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;I am deeply grateful to my classmates &lt;a class="reference external" href="https://github.com/itellaetxe"&gt;Iñigo Tellaetxe Elorriaga&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin Roy&lt;/a&gt;, and &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka&lt;/a&gt; for their insightful suggestions and comments on my work.
Special thanks to my mentor, &lt;a class="reference external" href="https://github.com//skoudoro"&gt;Serge Koudoro&lt;/a&gt;, whose guidance and support enabled me to meet the challenges of this project.
Their combined efforts have greatly contributed to my progress, and I appreciate their continued help.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-happens-next"&gt;
&lt;h2&gt;What happens next?&lt;/h2&gt;
&lt;p&gt;For week 3, I plan to :&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Ensure that the &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;warn_on_args_to_kwargs&lt;/span&gt;&lt;/code&gt; decorator is applied consistently in all necessary functions.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Continue to update the calling of these functions in the code to maintain consistency and avoid warnings.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Refine decorator as necessary based on feedback and testing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Start implementing lazy loading functionality based on my research to optimize performance.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;🥰 Thank you for taking the time to follow my progress. Your feedback is always welcome and I look forward to sharing more updates with you next week.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-15-week2-wachiou-bouraima.html"/>
    <summary>Welcome back to my Google Summer of Code (GSoC) 2024 journey! This week has been dedicated to refining and improving the work done so far, with a particular focus on the keyword_only decorator.</summary>
    <category term="google" label="google"/>
    <published>2024-06-15T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-06-week-1-robin.html</id>
    <title>Week 1: It officially begins…</title>
    <updated>2024-06-06T00:00:00+00:00</updated>
    <author>
      <name>Robin Roy</name>
    </author>
    <content type="html">&lt;section id="week-1-it-officially-begins"&gt;

&lt;p&gt;Hi, I’m &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin&lt;/a&gt; and this is my blog about week 1.&lt;/p&gt;
&lt;p&gt;My goal for week 1 was to start with &lt;a class="reference external" href="https://www.pinecone.io/learn/retrieval-augmented-generation/"&gt;Retrieval-Augmented Generation (RAG)&lt;/a&gt;, check different databases and host every endpoint. My week1 and week2 are very intertwined because I applied everything I did during week1 on week2. (I’m writing this blog midway through week2)&lt;/p&gt;
&lt;section id="why-phi-3-mini-4k-instruct"&gt;
&lt;h2&gt;why phi-3-mini-4k-instruct?&lt;/h2&gt;
&lt;p&gt;Before I detail everything I’ve done this week, I’ll explain why &lt;a class="reference external" href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct"&gt;phi-3 mini 4k&lt;/a&gt; was chosen as the LLM, I forgot to mention this in the last blog. Phi-3 is a small 3.8B 4k context model, it means it can work with 4k tokens(similar to words) at a time. Due to its small size, it runs fast both locally and on Huggingface. Performance wise comparatively with other opensource models, it performs decently well. In the &lt;a class="reference external" href="https://chat.lmsys.org/?leaderboard"&gt;LMSYS LLM leaderboard&lt;/a&gt; phi-3 mini 4k comes with an ELO of 1066 (59th position). But it achieves this as a small model.
I also tried Llama3-8B, it performs better than phi-3 mini with an ELO of 1153 and rank 22. But it is considerably slower for inference. Due to this, I chose phi-3 mini for now.&lt;/p&gt;
&lt;section id="things-i-did-week-1-and-some-week2"&gt;
&lt;h3&gt;Things I did week-1 (and some week2)&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Choosing the vector database&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I decided to choose &lt;a class="reference external" href="https://www.pinecone.io/"&gt;Pinecone&lt;/a&gt; as the vector DB because it had a very generous free tier. Other options on consideration were &lt;a class="reference external" href="https://github.com/pgvector/pgvector"&gt;pgvector&lt;/a&gt; and &lt;a class="reference external" href="https://www.trychroma.com/"&gt;chromadb&lt;/a&gt;, but they didn’t have a free tier.&lt;/p&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;PR Submissions and Review&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “2” (ordinal 2)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I also merged a &lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/891"&gt;PR&lt;/a&gt; on FURY which fixes a CI issue. I also spent time doing review of other PRs from my fellow GSoC mates.&lt;/p&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Deciding which embedding model to use&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “3” (ordinal 3)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;A good embedding model is necessary to generate embeddings which we then upsert into the DB. Ollama had embedding model support, but I found the catalogue very small and the models they provided were not powerful enough. Therefore I decided to try using HuggingFace Sentence Transformers.
Sentence Transformers have a very vibrant catalogue of models available of various sizes. I chose &lt;a class="reference external" href="https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5"&gt;gte-large-en-v1.5&lt;/a&gt; from Alibaba-NLP, an 8k context, 434 million parameter model. It only had a modest memory requirement of 1.62 GB.
Performance wise, it ranks 11th on the &lt;a class="reference external" href="https://huggingface.co/spaces/mteb/leaderboard"&gt;MTEB leaderboard&lt;/a&gt;. It is a very interesting model due to its size:performance ratio.&lt;/p&gt;
&lt;ol class="arabic simple" start="4"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hosting the embedding model&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “4” (ordinal 4)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;Hosting this sentence-transformer model was confusing. For some reason, the HF spaces were blocking the Python script from writing on &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;.cache&lt;/span&gt;&lt;/code&gt; folder. Docker container inside spaces runs with user id 1000 (non-root user), therefore I had to give it permission to download and store files.&lt;/p&gt;
&lt;p&gt;I’ve hosted 5 gunicorn workers to serve 5 parallel requests at a time. Since the model is small, this is possible.&lt;/p&gt;
&lt;ol class="arabic simple" start="5"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hosting the database endpoint&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “5” (ordinal 5)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;I wrapped the pinecone DB API into an endpoint so it’ll be easy to query and receive the results.
It is also configured to accept 5 concurrent requests although I could increase it a lot more.&lt;/p&gt;
&lt;p&gt;I upserted docstrings from &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;fury/actor.py&lt;/span&gt;&lt;/code&gt; into the vector DB for testing. So now, whenever you ask a question the model will use some &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;actor.py&lt;/span&gt;&lt;/code&gt; function to give you an answer. For now, it could be used like a semantic function search engine.&lt;/p&gt;
&lt;p&gt;I decided to abstract the DB endpoint to reduce the dependency on one provider. We can swap the providers as required and keep all other features running.&lt;/p&gt;
&lt;ol class="arabic simple" start="6"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Hosting Discord Bot&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2)&lt;/p&gt;
&lt;p&gt;Enumerated list start value not ordinal-1: “6” (ordinal 6)&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;So with this, all the endpoints are finally online. The bot has some issues, it is going offline midway for some reason. I’ll have to see why that happens.&lt;/p&gt;
&lt;p&gt;For some reason, Huggingface spaces decided to not start the bot script. Later a community admin from Huggingface told me to use their official bot implementation as a reference. This is why I had to use threading and gradio to get the bot running (migrating to docker can be done, but this is how they did it and I just took that for now).&lt;/p&gt;
&lt;p&gt;Huggingface spaces need a script to satisfy certain criteria to allow them to run, one of them is a non-blocking I/O on the main loop. So I had to move the discord bot to a new thread.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="connecting-all-of-them-together"&gt;
&lt;h2&gt;Connecting all of them together!&lt;/h2&gt;
&lt;dl class="simple"&gt;
&lt;dt&gt;So now we have 4 hosted services, all hosted on HuggingFace spaces:&lt;/dt&gt;&lt;dd&gt;&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Discord Bot&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;LLM API&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Embeddings API&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Database API&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Now we’ll have to connect them all to get an answer to the user query.&lt;/p&gt;
&lt;p&gt;This is the current architecture, there’s a lot of room for improvement here.&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;img src="https://github.com/fury-gl/fury-communication-assets/blob/main/gsoc_2024/7-6-2024-demo-architecture-gsoc-robin-week2.png?raw=true"&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;The Language Model takes the context and the user query, combines them to form an answer and returns to the user through discord (for now). Maybe moving the core logic from discord bot to a separate node might be good, and connect discord/github/X to that node.
The database takes embeddings and do an Approximate Nearest Neighbor search (a variant of KNN) and returns top-k results (k=3 for now).&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;&lt;iframe src="https://github.com/robinroy03/fury-discord-bot/assets/115863770/48f1136d-18a5-45ee-aa22-0a3f6426d575" width="640" height="390" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;section id="what-is-coming-up-next-week"&gt;
&lt;h3&gt;What is coming up next week?&lt;/h3&gt;
&lt;p&gt;Answer quality improvements. Also, the discord bot dies randomly, have to fix that also.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="did-you-get-stuck-anywhere"&gt;
&lt;h3&gt;Did you get stuck anywhere?&lt;/h3&gt;
&lt;p&gt;Was stuck in hosting models on Huggingface spaces, fixed it later.&lt;/p&gt;
&lt;p&gt;LINKS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-bot-discord/tree/main"&gt;Discord Bot&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-db-endpoint/tree/main"&gt;Database Repo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-embeddings-endpoint/tree/main"&gt;Embedding Repo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/robinroy03/fury-bot/tree/main"&gt;LLM Repo&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id1"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “retrieval-augmented generation (rag)”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.pinecone.io/learn/retrieval-augmented-generation/"&gt;Retrieval-Augmented Generation (RAG)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id2"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “phi-3 mini 4k”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct"&gt;phi-3 mini 4k&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id3"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “lmsys llm leaderboard”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://chat.lmsys.org/?leaderboard"&gt;LMSYS LLM leaderboard&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id4"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “pinecone”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.pinecone.io/"&gt;Pinecone&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id5"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “pgvector”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/pgvector/pgvector"&gt;pgvector&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id6"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “chromadb”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.trychroma.com/"&gt;chromadb&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id7"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “pr”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/fury-gl/fury/pull/891"&gt;PR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id8"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “gte-large-en-v1.5”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5"&gt;gte-large-en-v1.5&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;aside class="system-message"&gt;
&lt;p class="system-message-title"&gt;System Message: INFO/1 (&lt;span class="docutils literal"&gt;/home/runner/work/fury/fury/docs/source/posts/2024/2024-06-06-week-1-robin.rst&lt;/span&gt;, line 2); &lt;em&gt;&lt;a href="#id9"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Duplicate explicit target name: “mteb leaderboard”.&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;&lt;a class="reference external" href="https://huggingface.co/spaces/mteb/leaderboard"&gt;MTEB leaderboard&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-06-week-1-robin.html"/>
    <summary>Hi, I’m Robin and this is my blog about week 1.</summary>
    <category term="google" label="google"/>
    <published>2024-06-06T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://fury.gl/posts/2024/2024-06-06-week1-wachiou-bouraima.html</id>
    <title>WEEK 1: Progress and challenges at Google Summer of Code (GSoC) 2024</title>
    <updated>2024-06-06T00:00:00+00:00</updated>
    <author>
      <name>Wachiou BOURAIMA</name>
    </author>
    <content type="html">&lt;section id="week-1-progress-and-challenges-at-google-summer-of-code-gsoc-2024"&gt;

&lt;p&gt;Hello👋🏾,&lt;/p&gt;
&lt;p&gt;Welcome back to my Google Summer of Code (GSoC) 2024 journey!
This week has been filled with progress and challenges as I continue to work on modernizing the FURY code base.&lt;/p&gt;
&lt;section id="applying-the-keyword-only-decorator"&gt;
&lt;h2&gt;Applying the keyword_only decorator&lt;/h2&gt;
&lt;p&gt;My main task this week was to apply the keyword_only decorator to several functions.
The decorator ensures that all arguments except the first are keyword-only,
which helps to make the code clearer and parameter passing more explicit.
Some warnings appeared after applying this decorator, and to resolve them,
I updated all the code where these functions were called with the necessary format. This was a very important step in maintaining the integrity and functionality of the code base.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="managing-the-challenges-of-git-rebasing"&gt;
&lt;h2&gt;Managing the challenges of Git rebasing&lt;/h2&gt;
&lt;p&gt;Rebasing the branch I was working on was the other major activity of my week.
It was a real challenge because of the conflicts that arose and had to be resolved.
It involved a lot of research and problem-solving on how to resolve these conflicts,
which greatly enhanced my understanding of Git. It was a challenging but satisfying experience of version control management and complex mergers.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="peer-code-review"&gt;
&lt;h2&gt;Peer code review&lt;/h2&gt;
&lt;p&gt;In addition to my duties, I was also tasked with reviewing the code of my peers.
This exercise was very rewarding, as it enabled me to understand different coding styles and approaches.
The constructive comments and suggestions were beneficial not only for teammates,
but also for improving my own coding and reviewing skills.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="acknowledgements"&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;I would like to thank all my classmates: &lt;a class="reference external" href="https://github.com/itellaetxe"&gt;Iñigo Tellaetxe Elorriaga&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/robinroy03"&gt;Robin Roy&lt;/a&gt;, &lt;a class="reference external" href="https://github.com/deka27"&gt;Kaustav Deka&lt;/a&gt; and my guide: &lt;a class="reference external" href="https://github.com//skoudoro"&gt;Serge Koudoro&lt;/a&gt; for their constructive suggestions on my work.
Their ideas and suggestions were of great help to me and I am grateful for their support and advice.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-happens-next"&gt;
&lt;h2&gt;What happens next?&lt;/h2&gt;
&lt;p&gt;Here’s a summary of what I plan to do in week two:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Apply the keyword_only decorator to all other necessary functions.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Update the calling of these functions in the code to ensure consistency and avoid raising warnings.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rename the decorator with a more descriptive name.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add two parameters to the decorator, specifying from which version of FURY it will work.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;🥰Thanks for reading! Your comments are most welcome, and I look forward to giving you a sneak preview of my work next week.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
</content>
    <link href="https://fury.gl/posts/2024/2024-06-06-week1-wachiou-bouraima.html"/>
    <summary>Hello👋🏾,</summary>
    <category term="google" label="google"/>
    <published>2024-06-06T00:00:00+00:00</published>
  </entry>
</feed>
