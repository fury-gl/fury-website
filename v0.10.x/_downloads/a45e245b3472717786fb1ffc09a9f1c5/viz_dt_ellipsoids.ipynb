{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Display Tensor Ellipsoids for DTI using tensor_slicer vs ellipsoid actor\nThis tutorial is intended to show two ways of displaying diffusion tensor\nellipsoids for DTI visualization. The first is using the usual\n``tensor_slicer`` that allows us to slice many tensors as ellipsoids. The\nsecond is the generic ``ellipsoid`` actor that can be used to display different\namount of ellipsoids.\n\nWe start by importing the necessary modules:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import itertools\n\nimport numpy as np\n\nfrom dipy.io.image import load_nifti\n\nfrom fury import window, actor, ui\nfrom fury.actor import _fa, _color_fa\nfrom fury.data import fetch_viz_dmri, read_viz_dmri\nfrom fury.primitive import prim_sphere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we fetch and load the data needed to display the Diffusion Tensor\nImages.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fetch_viz_dmri()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The tensor ellipsoids are expressed as eigenvalues and eigenvectors which are\nthe decomposition of the diffusion tensor that describes the water diffusion\nwithin a voxel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "slice_evecs, _ = load_nifti(read_viz_dmri('slice_evecs.nii.gz'))\nslice_evals, _ = load_nifti(read_viz_dmri('slice_evals.nii.gz'))\nroi_evecs, _ = load_nifti(read_viz_dmri('roi_evecs.nii.gz'))\nroi_evals, _ = load_nifti(read_viz_dmri('roi_evals.nii.gz'))\nwhole_brain_evecs, _ = load_nifti(read_viz_dmri('whole_brain_evecs.nii.gz'))\nwhole_brain_evals, _ = load_nifti(read_viz_dmri('whole_brain_evals.nii.gz'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using tensor_slicer actor\nFirst we must define the 3 parameters needed to use the ``tensor_slicer``\nactor, which correspond to the eigenvalues, the eigenvectors, and the sphere.\nFor the sphere we use ``prim_sphere`` which provide vertices and triangles of\nthe spheres. These are labeled as 'repulsionN' with N been the number of\nvertices that made up the sphere, which have a standard number of 100, 200,\nand 724 vertices.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vertices, faces = prim_sphere('repulsion100', True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we need to provide a sphere object we create a class Sphere to which we\nassign the values obtained from vertices and faces.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Sphere:\n    def __init__(self, vertices, faces):\n        self.vertices = vertices\n        self.faces = faces\n\n\nsphere100 = Sphere(vertices, faces)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are ready to create the ``tensor_slicer`` actor with the values of a\nbrain slice. We also define the scale so that the tensors are not so large\nand overlap each other.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tensor_slice = actor.tensor_slicer(evals=slice_evals, evecs=slice_evecs,\n                                   sphere=sphere100, scale=.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we set up a new scene to add and visualize the tensor ellipsoids\ncreated.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scene = window.Scene()\nscene.background([255, 255, 255])\nscene.add(tensor_slice)\n\n# Create show manager\nshowm = window.ShowManager(scene, size=(600, 600))\n\n# Enables/disables interactive visualization\ninteractive = False\n\nif interactive:\n    showm.start()\n\nwindow.record(showm.scene, size=(600, 600), out_path='tensor_slice_100.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we zoom in at the scene to see with detail the tensor ellipsoids displayed\nwith the different spheres, we get the following results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scene.roll(10)\nscene.pitch(90)\nshowm = window.ShowManager(scene, size=(600, 600), order_transparent=True)\nshowm.scene.zoom(50)\n\nif interactive:\n    showm.render()\n    showm.start()\n\nwindow.record(showm.scene, out_path='tensor_slice_100_zoom.png',\n              size=(600, 300), reset_camera=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To render the same tensor slice using a different sphere we redefine the\nvertices and faces of the sphere using prim_sphere with other sphere\nspecification, as 'repulsion200' or 'repulsion724'.\n\nNow we clear the scene for the next visualization, and revert the scene\nrotations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "showm.scene.clear()\nshowm.scene.pitch(-90)\nshowm.scene.roll(-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using ellipsoid actor\nIn order to use the ``ellipsoid`` actor to display the same tensor slice we\nneed to set additional parameters. For this purpose, we define a helper\nfunction to facilitate the correct setting of the parameters before passing\nthem to the actor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_params(evecs, evals):\n    # We define the centers which corresponds to the ellipsoids positions.\n    valid_mask = np.abs(evecs).max(axis=(-2, -1)) > 0\n    indices = np.nonzero(valid_mask)\n    centers = np.asarray(indices).T\n\n    # We need to pass the data of the axes and lengths of the ellipsoid as a\n    # ndarray, so it is necessary to rearrange the data of the eigenvectors and\n    # eigenvalues.\n    fevecs = evecs[indices]\n    fevals = evals[indices]\n\n    # We need to define the colors of the ellipsoids following the default\n    # coloring in tensor_slicer that is uses _color_fa that is a way to map\n    # colors to each tensor based on the fractional anisotropy (FA) of each\n    # diffusion tensor.\n    colors = _color_fa(_fa(fevals), fevecs)\n\n    return centers, fevecs, fevals, colors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With this we now have the values we need to define the centers, axes,\nlengths, and colors of the ellipsoids.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "centers, evecs, evals, colors = get_params(slice_evecs, slice_evals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can use the ``ellipsoid`` actor to create the tensor ellipsoids as\nfollows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tensors = actor.ellipsoid(centers=centers, colors=colors, axes=evecs,\n                          lengths=evals, scales=.6)\nshowm.scene.add(tensors)\n\nif interactive:\n    showm.start()\n\nwindow.record(scene, size=(600, 600), out_path='tensor_slice_sdf.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, one can see that the same result is obtained, however there is a\ndifference in the visual quality and this is because the ``ellipsoid`` actor\nuses raymarching technique, so the objects that are generated are smoother\nsince they are not made with polygons but defined by an SDF function. Next we\ncan see in more detail the tensor ellipsoids generated.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scene.roll(10)\nscene.pitch(90)\nshowm = window.ShowManager(scene, size=(600, 600), order_transparent=True)\nshowm.scene.zoom(50)\n\nif interactive:\n    showm.render()\n    showm.start()\n\nwindow.record(showm.scene, out_path='tensor_slice_sdf_zoom.png',\n              size=(600, 300), reset_camera=False)\n\nshowm.scene.clear()\nshowm.scene.pitch(-90)\nshowm.scene.roll(-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visual quality comparison\nOne can see that there is a different on the visual quality of both ways of\ndisplaying tensors and this is because ``tensor_slicer`` uses polygons while\n``ellipsoid`` uses raymarching. Let's display both implementations at the\nsame time, so we can see this in more detail.\n\nWe first set up the required data and create the actors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mevals = np.array([1.4, 1.0, 0.35]) * 10 ** (-3)\nmevecs = np.array([[2/3, -2/3, 1/3], [1/3, 2/3, 2/3], [2/3, 1/3, -2/3]])\n\nevals = np.zeros((1, 1, 1, 3))\nevecs = np.zeros((1, 1, 1, 3, 3))\n\nevals[..., :] = mevals\nevecs[..., :, :] = mevecs\n\nvertices, faces = prim_sphere('repulsion200', True)\nsphere200 = Sphere(vertices, faces)\nvertices, faces = prim_sphere('repulsion724', True)\nsphere724 = Sphere(vertices, faces)\n\ntensor_100 = actor.tensor_slicer(evals=evals, evecs=evecs,\n                                 sphere=sphere100, scale=1.0)\ntensor_200 = actor.tensor_slicer(evals=evals, evecs=evecs,\n                                 sphere=sphere200, scale=1.0)\ntensor_724 = actor.tensor_slicer(evals=evals, evecs=evecs,\n                                 sphere=sphere724, scale=1.0)\n\ncenters, evecs, evals, colors = get_params(evecs=evecs, evals=evals)\ntensor_sdf = actor.ellipsoid(centers=centers, axes=evecs, lengths=evals,\n                             colors=colors, scales=2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we made use of `GridUI` which allows us to add the actors in a grid and\ninteract with them individually.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "objects = [tensor_100, tensor_200, tensor_724, tensor_sdf]\ntext = [actor.vector_text('Tensor 100'), actor.vector_text('Tensor 200'),\n        actor.vector_text('Tensor 724'), actor.vector_text('Tensor SDF')]\n\ngrid_ui = ui.GridUI(actors=objects, captions=text, cell_padding=.1,\n                    caption_offset=(-0.7, -2.5, 0), dim=(1, 4))\n\nscene = window.Scene()\nscene.background([255, 255, 255])\nscene.zoom(3.5)\nscene.set_camera(position=(3.2, -20, 12), focal_point=(3.2, 0.0, 0.0))\nshowm = window.ShowManager(scene, size=(560, 200))\nshowm.scene.add(grid_ui)\n\nif interactive:\n    showm.start()\n\nwindow.record(showm.scene, size=(560, 200), out_path='tensor_comparison.png',\n              reset_camera=False, magnification=2)\n\nshowm.scene.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize a larger amount of data\nWith ``tensor_slicer`` is possible to visualize more than one slice using\n``display_extent()``. Here we can see an example of a region of interest\n(ROI) using a sphere of 100 vertices.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tensor_roi = actor.tensor_slicer(evals=roi_evals, evecs=roi_evecs,\n                                 sphere=sphere100, scale=.3)\n\ndata_shape = roi_evals.shape[:3]\ntensor_roi.display_extent(\n    0, data_shape[0], 0, data_shape[1], 0, data_shape[2])\n\nshowm.size = (600, 600)\nshowm.scene.background([0, 0, 0])\nshowm.scene.add(tensor_roi)\nshowm.scene.azimuth(87)\n\nif interactive:\n    showm.start()\n\nwindow.record(showm.scene, size=(600, 600), out_path='tensor_roi_100.png')\n\nshowm.scene.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can do it also with a sphere of 200 vertices, but if we try to do it with\none of 724 the visualization can no longer be rendered. In contrast, we can\nvisualize the ROI with the ``ellipsoid`` actor without compromising the\nquality of the visualization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "centers, evecs, evals, colors = get_params(roi_evecs, roi_evals)\n\ntensors = actor.ellipsoid(centers=centers, colors=colors, axes=evecs,\n                          lengths=evals, scales=.6)\nshowm.scene.add(tensors)\n\nif interactive:\n    showm.start()\n\nwindow.record(showm.scene, size=(600, 600), out_path='tensor_roi_sdf.png')\n\nshowm.scene.clear()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In fact, although with a low performance, this actor allows us to visualize\nthe whole brain, which contains a much larger amount of data, to be exact\n184512 tensor ellipsoids are displayed at the same time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "centers, evecs, evals, colors = get_params(whole_brain_evecs,\n                                           whole_brain_evals)\n\n# We remove all the noise around the brain to have a better visualization.\nfil = [len(set(elem)) != 1 for elem in evals]\ncenters = np.array(list(itertools.compress(centers, fil)))\ncolors = np.array(list(itertools.compress(colors, fil)))\nevecs = np.array(list(itertools.compress(evecs, fil)))\nevals = np.array(list(itertools.compress(evals, fil)))\n\ntensors = actor.ellipsoid(centers=centers, colors=colors, axes=evecs,\n                          lengths=evals, scales=.6)\n\nscene = window.Scene()\nscene.add(tensors)\nscene.pitch(180)\nshowm = window.ShowManager(scene, size=(600, 600))\n\nif interactive:\n    showm.start()\n\nwindow.record(showm.scene, size=(600, 600), reset_camera=False,\n              out_path='tensor_whole_brain_sdf.png')\n\nshowm.scene.clear()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}